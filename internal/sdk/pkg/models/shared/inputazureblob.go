// Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"fmt"
)

// InputAzureBlobAuthenticationMethod - Enter connection string directly, or select a stored secret
type InputAzureBlobAuthenticationMethod string

const (
	InputAzureBlobAuthenticationMethodSecret InputAzureBlobAuthenticationMethod = "secret"
	InputAzureBlobAuthenticationMethodManual InputAzureBlobAuthenticationMethod = "manual"
)

func (e InputAzureBlobAuthenticationMethod) ToPointer() *InputAzureBlobAuthenticationMethod {
	return &e
}

func (e *InputAzureBlobAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "secret":
		fallthrough
	case "manual":
		*e = InputAzureBlobAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputAzureBlobAuthenticationMethod: %v", v)
	}
}

type InputAzureBlobConnections struct {
	// Select a Destination.
	Output string `json:"output"`
	// Select Pipeline or Pack. Optional.
	Pipeline *string `json:"pipeline,omitempty"`
}

type InputAzureBlobMetadata struct {
	// Field name
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

// InputAzureBlobPqCompression - Codec to use to compress the persisted data.
type InputAzureBlobPqCompression string

const (
	InputAzureBlobPqCompressionNone InputAzureBlobPqCompression = "none"
	InputAzureBlobPqCompressionGzip InputAzureBlobPqCompression = "gzip"
)

func (e InputAzureBlobPqCompression) ToPointer() *InputAzureBlobPqCompression {
	return &e
}

func (e *InputAzureBlobPqCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputAzureBlobPqCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputAzureBlobPqCompression: %v", v)
	}
}

// InputAzureBlobPqMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputAzureBlobPqMode string

const (
	InputAzureBlobPqModeSmart  InputAzureBlobPqMode = "smart"
	InputAzureBlobPqModeAlways InputAzureBlobPqMode = "always"
)

func (e InputAzureBlobPqMode) ToPointer() *InputAzureBlobPqMode {
	return &e
}

func (e *InputAzureBlobPqMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputAzureBlobPqMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputAzureBlobPqMode: %v", v)
	}
}

type InputAzureBlobPq struct {
	// The number of events to send downstream before committing that Stream has read them.
	CommitFrequency *int64 `json:"commitFrequency,omitempty"`
	// Codec to use to compress the persisted data.
	Compress *InputAzureBlobPqCompression `json:"compress,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk.
	MaxBufferSize *int64 `json:"maxBufferSize,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	MaxFileSize *string `json:"maxFileSize,omitempty"`
	// The maximum amount of disk space the queue is allowed to consume. Once reached, the system stops queueing and applies the fallback Queue-full behavior. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `json:"maxSize,omitempty"`
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputAzureBlobPqMode `json:"mode,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>.
	Path *string `json:"path,omitempty"`
}

type InputAzureBlobType string

const (
	InputAzureBlobTypeAzureBlob InputAzureBlobType = "azure_blob"
)

func (e InputAzureBlobType) ToPointer() *InputAzureBlobType {
	return &e
}

func (e *InputAzureBlobType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "azure_blob":
		*e = InputAzureBlobType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputAzureBlobType: %v", v)
	}
}

type InputAzureBlob struct {
	// Enter connection string directly, or select a stored secret
	AuthType *InputAzureBlobAuthenticationMethod `json:"authType,omitempty"`
	// A list of event breaking rulesets that will be applied, in order, to the input data stream.
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// Enter your Azure Storage account connection string. If left blank, Stream will fall back to env.AZURE_STORAGE_CONNECTION_STRING.
	ConnectionString *string `json:"connectionString,omitempty"`
	// Direct connections to Destinations, optionally via a Pipeline or a Pack.
	Connections []InputAzureBlobConnections `json:"connections,omitempty"`
	// Enable/disable this input
	Disabled *bool `json:"disabled,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Regex matching file names to download and process. Defaults to: .*
	FileFilter *string `json:"fileFilter,omitempty"`
	// Unique ID for this input
	ID *string `json:"id,omitempty"`
	// The maximum number of messages to return in a poll request. Azure storage queues never returns more messages than this value (however, fewer messages might be returned). Valid values: 1 to 32.
	MaxMessages *int64 `json:"maxMessages,omitempty"`
	// Fields to add to events from this input.
	Metadata []InputAzureBlobMetadata `json:"metadata,omitempty"`
	// The Number of receiver processes to run, the higher the number the better throughput at the expense of CPU overhead
	NumReceivers *int64 `json:"numReceivers,omitempty"`
	// The maximum time to wait for a Parquet file's chunk to be downloaded. Processing will end if a required chunk could not be downloaded within the time imposed by this setting.
	ParquetChunkDownloadTimeout *int64 `json:"parquetChunkDownloadTimeout,omitempty"`
	// Maximum file size for each Parquet chunk.
	ParquetChunkSizeMB *int64 `json:"parquetChunkSizeMB,omitempty"`
	// Pipeline to process data from this Source before sending it through the Routes.
	Pipeline *string           `json:"pipeline,omitempty"`
	Pq       *InputAzureBlobPq `json:"pq,omitempty"`
	// For details on Persistent Queues, see: [https://docs.cribl.io/stream/persistent-queues](https://docs.cribl.io/stream/persistent-queues)
	PqEnabled *bool `json:"pqEnabled,omitempty"`
	// The storage account queue name blob notifications will be read from. Value must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. E.g., referencing a Global Variable: `myQueue-${C.vars.myVar}`
	QueueName string `json:"queueName"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitempty"`
	// The duration (in seconds) which pollers should be validated and restarted if exited
	ServicePeriodSecs *int64 `json:"servicePeriodSecs,omitempty"`
	// Toggle to Yes to skip files that trigger a processing error. Defaults to No, which enables retries after processing errors.
	SkipOnError *bool `json:"skipOnError,omitempty"`
	// The amount of time (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel, before flushing the data stream out, as-is, to the Pipelines.
	StaleChannelFlushMs *int64 `json:"staleChannelFlushMs,omitempty"`
	// Add tags for filtering and grouping in @{product}.
	Streamtags []string `json:"streamtags,omitempty"`
	// Select (or create) a stored text secret
	TextSecret *string            `json:"textSecret,omitempty"`
	Type       InputAzureBlobType `json:"type"`
	// The duration (in seconds) that the received messages are hidden from subsequent retrieve requests after being retrieved by a ReceiveMessage request.
	VisibilityTimeout *int64 `json:"visibilityTimeout,omitempty"`
}
