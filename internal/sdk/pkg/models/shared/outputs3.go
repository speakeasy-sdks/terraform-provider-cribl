// Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"fmt"
)

// OutputS3AuthenticationMethod - AWS authentication method. Choose Auto to use IAM roles.
type OutputS3AuthenticationMethod string

const (
	OutputS3AuthenticationMethodSecret OutputS3AuthenticationMethod = "secret"
	OutputS3AuthenticationMethodManual OutputS3AuthenticationMethod = "manual"
)

func (e OutputS3AuthenticationMethod) ToPointer() *OutputS3AuthenticationMethod {
	return &e
}

func (e *OutputS3AuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "secret":
		fallthrough
	case "manual":
		*e = OutputS3AuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputS3AuthenticationMethod: %v", v)
	}
}

// OutputS3Compress - Choose data compression format to apply before moving files to final destination.
type OutputS3Compress string

const (
	OutputS3CompressNone OutputS3Compress = "none"
	OutputS3CompressGzip OutputS3Compress = "gzip"
)

func (e OutputS3Compress) ToPointer() *OutputS3Compress {
	return &e
}

func (e *OutputS3Compress) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputS3Compress(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputS3Compress: %v", v)
	}
}

// OutputS3DataFormat - Format of the output data.
type OutputS3DataFormat string

const (
	OutputS3DataFormatParquet OutputS3DataFormat = "parquet"
	OutputS3DataFormatRaw     OutputS3DataFormat = "raw"
	OutputS3DataFormatJSON    OutputS3DataFormat = "json"
)

func (e OutputS3DataFormat) ToPointer() *OutputS3DataFormat {
	return &e
}

func (e *OutputS3DataFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "parquet":
		fallthrough
	case "raw":
		fallthrough
	case "json":
		*e = OutputS3DataFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputS3DataFormat: %v", v)
	}
}

// OutputS3ObjectACL - Object ACL to assign to uploaded objects.
type OutputS3ObjectACL string

const (
	OutputS3ObjectACLPrivate                OutputS3ObjectACL = "private"
	OutputS3ObjectACLPublicRead             OutputS3ObjectACL = "public-read"
	OutputS3ObjectACLPublicReadWrite        OutputS3ObjectACL = "public-read-write"
	OutputS3ObjectACLAuthenticatedRead      OutputS3ObjectACL = "authenticated-read"
	OutputS3ObjectACLAwsExecRead            OutputS3ObjectACL = "aws-exec-read"
	OutputS3ObjectACLBucketOwnerRead        OutputS3ObjectACL = "bucket-owner-read"
	OutputS3ObjectACLBucketOwnerFullControl OutputS3ObjectACL = "bucket-owner-full-control"
)

func (e OutputS3ObjectACL) ToPointer() *OutputS3ObjectACL {
	return &e
}

func (e *OutputS3ObjectACL) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "private":
		fallthrough
	case "public-read":
		fallthrough
	case "public-read-write":
		fallthrough
	case "authenticated-read":
		fallthrough
	case "aws-exec-read":
		fallthrough
	case "bucket-owner-read":
		fallthrough
	case "bucket-owner-full-control":
		*e = OutputS3ObjectACL(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputS3ObjectACL: %v", v)
	}
}

// OutputS3BackpressureBehavior - Whether to block or drop events when all receivers are exerting backpressure.
type OutputS3BackpressureBehavior string

const (
	OutputS3BackpressureBehaviorBlock OutputS3BackpressureBehavior = "block"
	OutputS3BackpressureBehaviorDrop  OutputS3BackpressureBehavior = "drop"
)

func (e OutputS3BackpressureBehavior) ToPointer() *OutputS3BackpressureBehavior {
	return &e
}

func (e *OutputS3BackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputS3BackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputS3BackpressureBehavior: %v", v)
	}
}

// OutputS3DataPageVersion - Serialization format of data pages. Note that not all reader implentations support Data page V2.
type OutputS3DataPageVersion string

const (
	OutputS3DataPageVersionDataPageV1 OutputS3DataPageVersion = "DATA_PAGE_V1"
	OutputS3DataPageVersionDataPageV2 OutputS3DataPageVersion = "DATA_PAGE_V2"
)

func (e OutputS3DataPageVersion) ToPointer() *OutputS3DataPageVersion {
	return &e
}

func (e *OutputS3DataPageVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "DATA_PAGE_V1":
		fallthrough
	case "DATA_PAGE_V2":
		*e = OutputS3DataPageVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputS3DataPageVersion: %v", v)
	}
}

// OutputS3ParquetVersion - Determines which data types are supported and how they are represented.
type OutputS3ParquetVersion string

const (
	OutputS3ParquetVersionParquet10 OutputS3ParquetVersion = "PARQUET_1_0"
	OutputS3ParquetVersionParquet24 OutputS3ParquetVersion = "PARQUET_2_4"
	OutputS3ParquetVersionParquet26 OutputS3ParquetVersion = "PARQUET_2_6"
)

func (e OutputS3ParquetVersion) ToPointer() *OutputS3ParquetVersion {
	return &e
}

func (e *OutputS3ParquetVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "PARQUET_1_0":
		fallthrough
	case "PARQUET_2_4":
		fallthrough
	case "PARQUET_2_6":
		*e = OutputS3ParquetVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputS3ParquetVersion: %v", v)
	}
}

// OutputS3Region - Region where the S3 bucket is located.
type OutputS3Region string

const (
	OutputS3RegionUsEast1      OutputS3Region = "us-east-1"
	OutputS3RegionUsEast2      OutputS3Region = "us-east-2"
	OutputS3RegionUsWest1      OutputS3Region = "us-west-1"
	OutputS3RegionUsWest2      OutputS3Region = "us-west-2"
	OutputS3RegionAfSouth1     OutputS3Region = "af-south-1"
	OutputS3RegionCaCentral1   OutputS3Region = "ca-central-1"
	OutputS3RegionEuWest1      OutputS3Region = "eu-west-1"
	OutputS3RegionEuCentral1   OutputS3Region = "eu-central-1"
	OutputS3RegionEuWest2      OutputS3Region = "eu-west-2"
	OutputS3RegionEuSouth1     OutputS3Region = "eu-south-1"
	OutputS3RegionEuWest3      OutputS3Region = "eu-west-3"
	OutputS3RegionEuNorth1     OutputS3Region = "eu-north-1"
	OutputS3RegionApEast1      OutputS3Region = "ap-east-1"
	OutputS3RegionApNortheast1 OutputS3Region = "ap-northeast-1"
	OutputS3RegionApNortheast2 OutputS3Region = "ap-northeast-2"
	OutputS3RegionApSoutheast1 OutputS3Region = "ap-southeast-1"
	OutputS3RegionApSoutheast2 OutputS3Region = "ap-southeast-2"
	OutputS3RegionApSouth1     OutputS3Region = "ap-south-1"
	OutputS3RegionMeSouth1     OutputS3Region = "me-south-1"
	OutputS3RegionSaEast1      OutputS3Region = "sa-east-1"
	OutputS3RegionUsGovEast1   OutputS3Region = "us-gov-east-1"
	OutputS3RegionUsGovWest1   OutputS3Region = "us-gov-west-1"
)

func (e OutputS3Region) ToPointer() *OutputS3Region {
	return &e
}

func (e *OutputS3Region) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "us-east-1":
		fallthrough
	case "us-east-2":
		fallthrough
	case "us-west-1":
		fallthrough
	case "us-west-2":
		fallthrough
	case "af-south-1":
		fallthrough
	case "ca-central-1":
		fallthrough
	case "eu-west-1":
		fallthrough
	case "eu-central-1":
		fallthrough
	case "eu-west-2":
		fallthrough
	case "eu-south-1":
		fallthrough
	case "eu-west-3":
		fallthrough
	case "eu-north-1":
		fallthrough
	case "ap-east-1":
		fallthrough
	case "ap-northeast-1":
		fallthrough
	case "ap-northeast-2":
		fallthrough
	case "ap-southeast-1":
		fallthrough
	case "ap-southeast-2":
		fallthrough
	case "ap-south-1":
		fallthrough
	case "me-south-1":
		fallthrough
	case "sa-east-1":
		fallthrough
	case "us-gov-east-1":
		fallthrough
	case "us-gov-west-1":
		*e = OutputS3Region(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputS3Region: %v", v)
	}
}

// OutputS3ServerSideEncryption - Server-side encryption for uploaded objects.
type OutputS3ServerSideEncryption string

const (
	OutputS3ServerSideEncryptionAwsKms OutputS3ServerSideEncryption = "aws:kms"
)

func (e OutputS3ServerSideEncryption) ToPointer() *OutputS3ServerSideEncryption {
	return &e
}

func (e *OutputS3ServerSideEncryption) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "aws:kms":
		*e = OutputS3ServerSideEncryption(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputS3ServerSideEncryption: %v", v)
	}
}

// OutputS3SignatureVersion - Signature version to use for signing S3 requests.
type OutputS3SignatureVersion string

const (
	OutputS3SignatureVersionV2 OutputS3SignatureVersion = "v2"
	OutputS3SignatureVersionV4 OutputS3SignatureVersion = "v4"
)

func (e OutputS3SignatureVersion) ToPointer() *OutputS3SignatureVersion {
	return &e
}

func (e *OutputS3SignatureVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = OutputS3SignatureVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputS3SignatureVersion: %v", v)
	}
}

// OutputS3StorageClass - Storage class to select for uploaded objects.
type OutputS3StorageClass string

const (
	OutputS3StorageClassStandard           OutputS3StorageClass = "STANDARD"
	OutputS3StorageClassReducedRedundancy  OutputS3StorageClass = "REDUCED_REDUNDANCY"
	OutputS3StorageClassStandardIa         OutputS3StorageClass = "STANDARD_IA"
	OutputS3StorageClassOnezoneIa          OutputS3StorageClass = "ONEZONE_IA"
	OutputS3StorageClassIntelligentTiering OutputS3StorageClass = "INTELLIGENT_TIERING"
	OutputS3StorageClassGlacier            OutputS3StorageClass = "GLACIER"
	OutputS3StorageClassDeepArchive        OutputS3StorageClass = "DEEP_ARCHIVE"
)

func (e OutputS3StorageClass) ToPointer() *OutputS3StorageClass {
	return &e
}

func (e *OutputS3StorageClass) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "STANDARD":
		fallthrough
	case "REDUCED_REDUNDANCY":
		fallthrough
	case "STANDARD_IA":
		fallthrough
	case "ONEZONE_IA":
		fallthrough
	case "INTELLIGENT_TIERING":
		fallthrough
	case "GLACIER":
		fallthrough
	case "DEEP_ARCHIVE":
		*e = OutputS3StorageClass(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputS3StorageClass: %v", v)
	}
}

type OutputS3Type string

const (
	OutputS3TypeS3 OutputS3Type = "s3"
)

func (e OutputS3Type) ToPointer() *OutputS3Type {
	return &e
}

func (e *OutputS3Type) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "s3":
		*e = OutputS3Type(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputS3Type: %v", v)
	}
}

type OutputS3 struct {
	// Append output's ID to staging location.
	AddIDToStagePath *bool `json:"addIdToStagePath,omitempty"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Access key. This value can be a constant or a JavaScript expression(e.g., `${C.env.SOME_ACCESS_KEY}`).
	AwsAPIKey *string `json:"awsApiKey,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *OutputS3AuthenticationMethod `json:"awsAuthenticationMethod,omitempty"`
	// Select (or create) a stored secret that references your access key and secret key.
	AwsSecret *string `json:"awsSecret,omitempty"`
	// Secret key. This value can be a constant or a JavaScript expression(e.g., `${C.env.SOME_SECRET}`).
	AwsSecretKey *string `json:"awsSecretKey,omitempty"`
	// JavaScript expression to define the output filename prefix (can be constant).
	BaseFileName *string `json:"baseFileName,omitempty"`
	// Name of the destination S3 bucket. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. E.g., referencing a Global Variable: `myBucket-${C.vars.myVar}`.
	Bucket string `json:"bucket"`
	// Choose data compression format to apply before moving files to final destination.
	Compress *OutputS3Compress `json:"compress,omitempty"`
	// Prefix to append to files before uploading. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. E.g., referencing a Global Variable: `myKeyPrefix-${C.vars.myVar}`.
	DestPath string `json:"destPath"`
	// How often (secs) to clean-up empty directories when 'Remove Staging Dirs' is enabled.
	EmptyDirCleanupSec *int64 `json:"emptyDirCleanupSec,omitempty"`
	// Use Assume Role credentials to access S3
	EnableAssumeRole *bool `json:"enableAssumeRole,omitempty"`
	// S3 service endpoint. If empty, defaults to AWS' Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`)
	FileNameSuffix *string `json:"fileNameSuffix,omitempty"`
	// Format of the output data.
	Format *OutputS3DataFormat `json:"format,omitempty"`
	// Unique ID for this output
	ID *string `json:"id,omitempty"`
	// ID or ARN of the KMS customer-managed key to use for encryption
	KmsKeyID *string `json:"kmsKeyId,omitempty"`
	// Maximum number of parts to upload in parallel per file. Minimum part size is 5MB.
	MaxConcurrentFileParts *int64 `json:"maxConcurrentFileParts,omitempty"`
	// Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
	MaxFileIdleTimeSec *int64 `json:"maxFileIdleTimeSec,omitempty"`
	// Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
	MaxFileOpenTimeSec *int64 `json:"maxFileOpenTimeSec,omitempty"`
	// Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
	MaxFileSizeMB *int64 `json:"maxFileSizeMB,omitempty"`
	// Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
	MaxOpenFiles *int64 `json:"maxOpenFiles,omitempty"`
	// Object ACL to assign to uploaded objects.
	ObjectACL *OutputS3ObjectACL `json:"objectACL,omitempty"`
	// Whether to block or drop events when all receivers are exerting backpressure.
	OnBackpressure *OutputS3BackpressureBehavior `json:"onBackpressure,omitempty"`
	// Serialization format of data pages. Note that not all reader implentations support Data page V2.
	ParquetDataPageVersion *OutputS3DataPageVersion `json:"parquetDataPageVersion,omitempty"`
	// Ideal memory size for page segments. E.g., 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression. Imposes a target, not a strict limit; the final size of a row group may be larger or smaller.
	ParquetPageSize *string `json:"parquetPageSize,omitempty"`
	// Ideal memory size for row group segments. E.g., 128MB or 1GB. Affects memory use when writing. Imposes a target, not a strict limit; the final size of a row group may be larger or smaller.
	ParquetRowGroupSize *string `json:"parquetRowGroupSize,omitempty"`
	// Determines which data types are supported and how they are represented.
	ParquetVersion *OutputS3ParquetVersion `json:"parquetVersion,omitempty"`
	// JS expression defining how files are partitioned and organized. Default is date-based. If blank, Stream will fall back to the event's __partition field value – if present – otherwise to each location's root directory.
	PartitionExpr *string `json:"partitionExpr,omitempty"`
	// Pipeline to process data before sending out to this output.
	Pipeline *string `json:"pipeline,omitempty"`
	// Region where the S3 bucket is located.
	Region *OutputS3Region `json:"region,omitempty"`
	// Whether to reject certificates that cannot be verified against a valid CA (e.g., self-signed certificates).
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Remove empty staging directories after moving files.
	RemoveEmptyDirs *bool `json:"removeEmptyDirs,omitempty"`
	// Whether to reuse connections between requests, which can improve performance.
	ReuseConnections *bool `json:"reuseConnections,omitempty"`
	// Server-side encryption for uploaded objects.
	ServerSideEncryption *OutputS3ServerSideEncryption `json:"serverSideEncryption,omitempty"`
	// To log rows that @{product} skips due to data mismatch, first set logging to Debug, then toggle this on. Logs up to 20 unique rows.
	ShouldLogInvalidRows *bool `json:"shouldLogInvalidRows,omitempty"`
	// Signature version to use for signing S3 requests.
	SignatureVersion *OutputS3SignatureVersion `json:"signatureVersion,omitempty"`
	Spacer           *string                   `json:"spacer,omitempty"`
	// Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant stable storage.
	StagePath string `json:"stagePath"`
	// Storage class to select for uploaded objects.
	StorageClass *OutputS3StorageClass `json:"storageClass,omitempty"`
	// Add tags for filtering and grouping in @{product}.
	Streamtags []string `json:"streamtags,omitempty"`
	// Set of fields to automatically add to events using this output. E.g.: cribl_pipe, c*. Wildcards supported.
	SystemFields []string      `json:"systemFields,omitempty"`
	Type         *OutputS3Type `json:"type,omitempty"`
}
