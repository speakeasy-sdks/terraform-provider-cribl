// Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"fmt"
)

// OutputSecurityLakeAuthenticationMethod - AWS authentication method. Choose Auto to use IAM roles.
type OutputSecurityLakeAuthenticationMethod string

const (
	OutputSecurityLakeAuthenticationMethodSecret OutputSecurityLakeAuthenticationMethod = "secret"
	OutputSecurityLakeAuthenticationMethodManual OutputSecurityLakeAuthenticationMethod = "manual"
)

func (e OutputSecurityLakeAuthenticationMethod) ToPointer() *OutputSecurityLakeAuthenticationMethod {
	return &e
}

func (e *OutputSecurityLakeAuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "secret":
		fallthrough
	case "manual":
		*e = OutputSecurityLakeAuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSecurityLakeAuthenticationMethod: %v", v)
	}
}

// OutputSecurityLakeObjectACL - Object ACL to assign to uploaded objects.
type OutputSecurityLakeObjectACL string

const (
	OutputSecurityLakeObjectACLPrivate                OutputSecurityLakeObjectACL = "private"
	OutputSecurityLakeObjectACLPublicRead             OutputSecurityLakeObjectACL = "public-read"
	OutputSecurityLakeObjectACLPublicReadWrite        OutputSecurityLakeObjectACL = "public-read-write"
	OutputSecurityLakeObjectACLAuthenticatedRead      OutputSecurityLakeObjectACL = "authenticated-read"
	OutputSecurityLakeObjectACLAwsExecRead            OutputSecurityLakeObjectACL = "aws-exec-read"
	OutputSecurityLakeObjectACLBucketOwnerRead        OutputSecurityLakeObjectACL = "bucket-owner-read"
	OutputSecurityLakeObjectACLBucketOwnerFullControl OutputSecurityLakeObjectACL = "bucket-owner-full-control"
)

func (e OutputSecurityLakeObjectACL) ToPointer() *OutputSecurityLakeObjectACL {
	return &e
}

func (e *OutputSecurityLakeObjectACL) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "private":
		fallthrough
	case "public-read":
		fallthrough
	case "public-read-write":
		fallthrough
	case "authenticated-read":
		fallthrough
	case "aws-exec-read":
		fallthrough
	case "bucket-owner-read":
		fallthrough
	case "bucket-owner-full-control":
		*e = OutputSecurityLakeObjectACL(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSecurityLakeObjectACL: %v", v)
	}
}

// OutputSecurityLakeBackpressureBehavior - Whether to block or drop events when all receivers are exerting backpressure.
type OutputSecurityLakeBackpressureBehavior string

const (
	OutputSecurityLakeBackpressureBehaviorBlock OutputSecurityLakeBackpressureBehavior = "block"
	OutputSecurityLakeBackpressureBehaviorDrop  OutputSecurityLakeBackpressureBehavior = "drop"
)

func (e OutputSecurityLakeBackpressureBehavior) ToPointer() *OutputSecurityLakeBackpressureBehavior {
	return &e
}

func (e *OutputSecurityLakeBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputSecurityLakeBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSecurityLakeBackpressureBehavior: %v", v)
	}
}

// OutputSecurityLakeDataPageVersion - Serialization format of data pages. Note that not all reader implentations support Data page V2.
type OutputSecurityLakeDataPageVersion string

const (
	OutputSecurityLakeDataPageVersionDataPageV1 OutputSecurityLakeDataPageVersion = "DATA_PAGE_V1"
	OutputSecurityLakeDataPageVersionDataPageV2 OutputSecurityLakeDataPageVersion = "DATA_PAGE_V2"
)

func (e OutputSecurityLakeDataPageVersion) ToPointer() *OutputSecurityLakeDataPageVersion {
	return &e
}

func (e *OutputSecurityLakeDataPageVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "DATA_PAGE_V1":
		fallthrough
	case "DATA_PAGE_V2":
		*e = OutputSecurityLakeDataPageVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSecurityLakeDataPageVersion: %v", v)
	}
}

// OutputSecurityLakeParquetVersion - Determines which data types are supported and how they are represented.
type OutputSecurityLakeParquetVersion string

const (
	OutputSecurityLakeParquetVersionParquet10 OutputSecurityLakeParquetVersion = "PARQUET_1_0"
	OutputSecurityLakeParquetVersionParquet24 OutputSecurityLakeParquetVersion = "PARQUET_2_4"
	OutputSecurityLakeParquetVersionParquet26 OutputSecurityLakeParquetVersion = "PARQUET_2_6"
)

func (e OutputSecurityLakeParquetVersion) ToPointer() *OutputSecurityLakeParquetVersion {
	return &e
}

func (e *OutputSecurityLakeParquetVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "PARQUET_1_0":
		fallthrough
	case "PARQUET_2_4":
		fallthrough
	case "PARQUET_2_6":
		*e = OutputSecurityLakeParquetVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSecurityLakeParquetVersion: %v", v)
	}
}

// OutputSecurityLakeRegion - Region where the Amazon Security Lake is located.
type OutputSecurityLakeRegion string

const (
	OutputSecurityLakeRegionUsEast1      OutputSecurityLakeRegion = "us-east-1"
	OutputSecurityLakeRegionUsEast2      OutputSecurityLakeRegion = "us-east-2"
	OutputSecurityLakeRegionUsWest1      OutputSecurityLakeRegion = "us-west-1"
	OutputSecurityLakeRegionUsWest2      OutputSecurityLakeRegion = "us-west-2"
	OutputSecurityLakeRegionAfSouth1     OutputSecurityLakeRegion = "af-south-1"
	OutputSecurityLakeRegionCaCentral1   OutputSecurityLakeRegion = "ca-central-1"
	OutputSecurityLakeRegionEuWest1      OutputSecurityLakeRegion = "eu-west-1"
	OutputSecurityLakeRegionEuCentral1   OutputSecurityLakeRegion = "eu-central-1"
	OutputSecurityLakeRegionEuWest2      OutputSecurityLakeRegion = "eu-west-2"
	OutputSecurityLakeRegionEuSouth1     OutputSecurityLakeRegion = "eu-south-1"
	OutputSecurityLakeRegionEuWest3      OutputSecurityLakeRegion = "eu-west-3"
	OutputSecurityLakeRegionEuNorth1     OutputSecurityLakeRegion = "eu-north-1"
	OutputSecurityLakeRegionApEast1      OutputSecurityLakeRegion = "ap-east-1"
	OutputSecurityLakeRegionApNortheast1 OutputSecurityLakeRegion = "ap-northeast-1"
	OutputSecurityLakeRegionApNortheast2 OutputSecurityLakeRegion = "ap-northeast-2"
	OutputSecurityLakeRegionApSoutheast1 OutputSecurityLakeRegion = "ap-southeast-1"
	OutputSecurityLakeRegionApSoutheast2 OutputSecurityLakeRegion = "ap-southeast-2"
	OutputSecurityLakeRegionApSouth1     OutputSecurityLakeRegion = "ap-south-1"
	OutputSecurityLakeRegionMeSouth1     OutputSecurityLakeRegion = "me-south-1"
	OutputSecurityLakeRegionSaEast1      OutputSecurityLakeRegion = "sa-east-1"
	OutputSecurityLakeRegionUsGovEast1   OutputSecurityLakeRegion = "us-gov-east-1"
	OutputSecurityLakeRegionUsGovWest1   OutputSecurityLakeRegion = "us-gov-west-1"
)

func (e OutputSecurityLakeRegion) ToPointer() *OutputSecurityLakeRegion {
	return &e
}

func (e *OutputSecurityLakeRegion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "us-east-1":
		fallthrough
	case "us-east-2":
		fallthrough
	case "us-west-1":
		fallthrough
	case "us-west-2":
		fallthrough
	case "af-south-1":
		fallthrough
	case "ca-central-1":
		fallthrough
	case "eu-west-1":
		fallthrough
	case "eu-central-1":
		fallthrough
	case "eu-west-2":
		fallthrough
	case "eu-south-1":
		fallthrough
	case "eu-west-3":
		fallthrough
	case "eu-north-1":
		fallthrough
	case "ap-east-1":
		fallthrough
	case "ap-northeast-1":
		fallthrough
	case "ap-northeast-2":
		fallthrough
	case "ap-southeast-1":
		fallthrough
	case "ap-southeast-2":
		fallthrough
	case "ap-south-1":
		fallthrough
	case "me-south-1":
		fallthrough
	case "sa-east-1":
		fallthrough
	case "us-gov-east-1":
		fallthrough
	case "us-gov-west-1":
		*e = OutputSecurityLakeRegion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSecurityLakeRegion: %v", v)
	}
}

// OutputSecurityLakeServerSideEncryption - Server-side encryption for uploaded objects.
type OutputSecurityLakeServerSideEncryption string

const (
	OutputSecurityLakeServerSideEncryptionAwsKms OutputSecurityLakeServerSideEncryption = "aws:kms"
)

func (e OutputSecurityLakeServerSideEncryption) ToPointer() *OutputSecurityLakeServerSideEncryption {
	return &e
}

func (e *OutputSecurityLakeServerSideEncryption) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "aws:kms":
		*e = OutputSecurityLakeServerSideEncryption(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSecurityLakeServerSideEncryption: %v", v)
	}
}

// OutputSecurityLakeSignatureVersion - Signature version to use for signing Amazon Security Lake requests.
type OutputSecurityLakeSignatureVersion string

const (
	OutputSecurityLakeSignatureVersionV2 OutputSecurityLakeSignatureVersion = "v2"
	OutputSecurityLakeSignatureVersionV4 OutputSecurityLakeSignatureVersion = "v4"
)

func (e OutputSecurityLakeSignatureVersion) ToPointer() *OutputSecurityLakeSignatureVersion {
	return &e
}

func (e *OutputSecurityLakeSignatureVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = OutputSecurityLakeSignatureVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSecurityLakeSignatureVersion: %v", v)
	}
}

// OutputSecurityLakeStorageClass - Storage class to select for uploaded objects.
type OutputSecurityLakeStorageClass string

const (
	OutputSecurityLakeStorageClassStandard           OutputSecurityLakeStorageClass = "STANDARD"
	OutputSecurityLakeStorageClassReducedRedundancy  OutputSecurityLakeStorageClass = "REDUCED_REDUNDANCY"
	OutputSecurityLakeStorageClassStandardIa         OutputSecurityLakeStorageClass = "STANDARD_IA"
	OutputSecurityLakeStorageClassOnezoneIa          OutputSecurityLakeStorageClass = "ONEZONE_IA"
	OutputSecurityLakeStorageClassIntelligentTiering OutputSecurityLakeStorageClass = "INTELLIGENT_TIERING"
	OutputSecurityLakeStorageClassGlacier            OutputSecurityLakeStorageClass = "GLACIER"
	OutputSecurityLakeStorageClassDeepArchive        OutputSecurityLakeStorageClass = "DEEP_ARCHIVE"
)

func (e OutputSecurityLakeStorageClass) ToPointer() *OutputSecurityLakeStorageClass {
	return &e
}

func (e *OutputSecurityLakeStorageClass) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "STANDARD":
		fallthrough
	case "REDUCED_REDUNDANCY":
		fallthrough
	case "STANDARD_IA":
		fallthrough
	case "ONEZONE_IA":
		fallthrough
	case "INTELLIGENT_TIERING":
		fallthrough
	case "GLACIER":
		fallthrough
	case "DEEP_ARCHIVE":
		*e = OutputSecurityLakeStorageClass(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSecurityLakeStorageClass: %v", v)
	}
}

type OutputSecurityLakeType string

const (
	OutputSecurityLakeTypeSecurityLake OutputSecurityLakeType = "security_lake"
)

func (e OutputSecurityLakeType) ToPointer() *OutputSecurityLakeType {
	return &e
}

func (e *OutputSecurityLakeType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "security_lake":
		*e = OutputSecurityLakeType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputSecurityLakeType: %v", v)
	}
}

type OutputSecurityLake struct {
	// ID of the AWS account whose data the Destination will write to Security Lake. This should have been configured when creating the Amazon Security Lake custom source.
	AccountID string `json:"accountId"`
	// Append output's ID to staging location.
	AddIDToStagePath *bool `json:"addIdToStagePath,omitempty"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn string `json:"assumeRoleArn"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Access key. This value can be a constant or a JavaScript expression(e.g., `${C.env.SOME_ACCESS_KEY}`).
	AwsAPIKey *string `json:"awsApiKey,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *OutputSecurityLakeAuthenticationMethod `json:"awsAuthenticationMethod,omitempty"`
	// Select (or create) a stored secret that references your access key and secret key.
	AwsSecret *string `json:"awsSecret,omitempty"`
	// Secret key
	AwsSecretKey *string `json:"awsSecretKey,omitempty"`
	// JavaScript expression to define the output filename prefix (can be constant).
	BaseFileName *string `json:"baseFileName,omitempty"`
	// Name of the destination S3 bucket. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. E.g., referencing a Global Variable: `myBucket-${C.vars.myVar}`.
	Bucket string `json:"bucket"`
	// Name of the custom source configured in Amazon Security Lake
	CustomSource string `json:"customSource"`
	// How often (secs) to clean-up empty directories when 'Remove Staging Dirs' is enabled.
	EmptyDirCleanupSec *int64 `json:"emptyDirCleanupSec,omitempty"`
	// Use Assume Role credentials to access S3
	EnableAssumeRole *bool `json:"enableAssumeRole,omitempty"`
	// Amazon Security Lake service endpoint. If empty, defaults to AWS' Region-specific endpoint. Otherwise, it must point to Amazon Security Lake-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Unique ID for this output
	ID *string `json:"id,omitempty"`
	// ID or ARN of the KMS customer-managed key to use for encryption
	KmsKeyID *string `json:"kmsKeyId,omitempty"`
	// Maximum number of parts to upload in parallel per file. Minimum part size is 5MB.
	MaxConcurrentFileParts *int64 `json:"maxConcurrentFileParts,omitempty"`
	// Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
	MaxFileIdleTimeSec *int64 `json:"maxFileIdleTimeSec,omitempty"`
	// Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
	MaxFileOpenTimeSec *int64 `json:"maxFileOpenTimeSec,omitempty"`
	// Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
	MaxFileSizeMB *int64 `json:"maxFileSizeMB,omitempty"`
	// Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
	MaxOpenFiles *int64 `json:"maxOpenFiles,omitempty"`
	// Object ACL to assign to uploaded objects.
	ObjectACL *OutputSecurityLakeObjectACL `json:"objectACL,omitempty"`
	// Whether to block or drop events when all receivers are exerting backpressure.
	OnBackpressure *OutputSecurityLakeBackpressureBehavior `json:"onBackpressure,omitempty"`
	// Serialization format of data pages. Note that not all reader implentations support Data page V2.
	ParquetDataPageVersion *OutputSecurityLakeDataPageVersion `json:"parquetDataPageVersion,omitempty"`
	// Ideal memory size for page segments. E.g., 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression. Imposes a target, not a strict limit; the final size of a row group may be larger or smaller.
	ParquetPageSize *string `json:"parquetPageSize,omitempty"`
	// Ideal memory size for row group segments. E.g., 128MB or 1GB. Affects memory use when writing. Imposes a target, not a strict limit; the final size of a row group may be larger or smaller.
	ParquetRowGroupSize *string `json:"parquetRowGroupSize,omitempty"`
	// Determines which data types are supported and how they are represented.
	ParquetVersion *OutputSecurityLakeParquetVersion `json:"parquetVersion,omitempty"`
	// Pipeline to process data before sending out to this output.
	Pipeline *string `json:"pipeline,omitempty"`
	// Region where the Amazon Security Lake is located.
	Region OutputSecurityLakeRegion `json:"region"`
	// Whether to reject certificates that cannot be verified against a valid CA (e.g., self-signed certificates).
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Remove empty staging directories after moving files.
	RemoveEmptyDirs *bool `json:"removeEmptyDirs,omitempty"`
	// Whether to reuse connections between requests, which can improve performance.
	ReuseConnections *bool `json:"reuseConnections,omitempty"`
	// Server-side encryption for uploaded objects.
	ServerSideEncryption *OutputSecurityLakeServerSideEncryption `json:"serverSideEncryption,omitempty"`
	// Signature version to use for signing Amazon Security Lake requests.
	SignatureVersion *OutputSecurityLakeSignatureVersion `json:"signatureVersion,omitempty"`
	Spacer           *string                             `json:"spacer,omitempty"`
	// Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant stable storage.
	StagePath string `json:"stagePath"`
	// Storage class to select for uploaded objects.
	StorageClass *OutputSecurityLakeStorageClass `json:"storageClass,omitempty"`
	// Add tags for filtering and grouping in @{product}.
	Streamtags []string `json:"streamtags,omitempty"`
	// Set of fields to automatically add to events using this output. E.g.: cribl_pipe, c*. Wildcards supported. These fields are added as dimensions and labels to generated metrics and logs respectively.
	SystemFields []string                `json:"systemFields,omitempty"`
	Type         *OutputSecurityLakeType `json:"type,omitempty"`
}
