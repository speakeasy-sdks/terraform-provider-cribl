// Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"fmt"
)

// OutputFilesystemCompress - Choose data compression format to apply before moving files to final destination.
type OutputFilesystemCompress string

const (
	OutputFilesystemCompressNone OutputFilesystemCompress = "none"
	OutputFilesystemCompressGzip OutputFilesystemCompress = "gzip"
)

func (e OutputFilesystemCompress) ToPointer() *OutputFilesystemCompress {
	return &e
}

func (e *OutputFilesystemCompress) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputFilesystemCompress(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputFilesystemCompress: %v", v)
	}
}

// OutputFilesystemDataFormat - Format of the output data.
type OutputFilesystemDataFormat string

const (
	OutputFilesystemDataFormatParquet OutputFilesystemDataFormat = "parquet"
	OutputFilesystemDataFormatRaw     OutputFilesystemDataFormat = "raw"
	OutputFilesystemDataFormatJSON    OutputFilesystemDataFormat = "json"
)

func (e OutputFilesystemDataFormat) ToPointer() *OutputFilesystemDataFormat {
	return &e
}

func (e *OutputFilesystemDataFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "parquet":
		fallthrough
	case "raw":
		fallthrough
	case "json":
		*e = OutputFilesystemDataFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputFilesystemDataFormat: %v", v)
	}
}

// OutputFilesystemBackpressureBehavior - Whether to block or drop events when all receivers are exerting backpressure.
type OutputFilesystemBackpressureBehavior string

const (
	OutputFilesystemBackpressureBehaviorBlock OutputFilesystemBackpressureBehavior = "block"
	OutputFilesystemBackpressureBehaviorDrop  OutputFilesystemBackpressureBehavior = "drop"
)

func (e OutputFilesystemBackpressureBehavior) ToPointer() *OutputFilesystemBackpressureBehavior {
	return &e
}

func (e *OutputFilesystemBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputFilesystemBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputFilesystemBackpressureBehavior: %v", v)
	}
}

// OutputFilesystemDataPageVersion - Serialization format of data pages. Note that not all reader implentations support Data page V2.
type OutputFilesystemDataPageVersion string

const (
	OutputFilesystemDataPageVersionDataPageV1 OutputFilesystemDataPageVersion = "DATA_PAGE_V1"
	OutputFilesystemDataPageVersionDataPageV2 OutputFilesystemDataPageVersion = "DATA_PAGE_V2"
)

func (e OutputFilesystemDataPageVersion) ToPointer() *OutputFilesystemDataPageVersion {
	return &e
}

func (e *OutputFilesystemDataPageVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "DATA_PAGE_V1":
		fallthrough
	case "DATA_PAGE_V2":
		*e = OutputFilesystemDataPageVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputFilesystemDataPageVersion: %v", v)
	}
}

// OutputFilesystemParquetVersion - Determines which data types are supported and how they are represented.
type OutputFilesystemParquetVersion string

const (
	OutputFilesystemParquetVersionParquet10 OutputFilesystemParquetVersion = "PARQUET_1_0"
	OutputFilesystemParquetVersionParquet24 OutputFilesystemParquetVersion = "PARQUET_2_4"
	OutputFilesystemParquetVersionParquet26 OutputFilesystemParquetVersion = "PARQUET_2_6"
)

func (e OutputFilesystemParquetVersion) ToPointer() *OutputFilesystemParquetVersion {
	return &e
}

func (e *OutputFilesystemParquetVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "PARQUET_1_0":
		fallthrough
	case "PARQUET_2_4":
		fallthrough
	case "PARQUET_2_6":
		*e = OutputFilesystemParquetVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputFilesystemParquetVersion: %v", v)
	}
}

type OutputFilesystemType string

const (
	OutputFilesystemTypeFilesystem OutputFilesystemType = "filesystem"
)

func (e OutputFilesystemType) ToPointer() *OutputFilesystemType {
	return &e
}

func (e *OutputFilesystemType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "filesystem":
		*e = OutputFilesystemType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputFilesystemType: %v", v)
	}
}

type OutputFilesystem struct {
	// Append output's ID to staging location.
	AddIDToStagePath *bool `json:"addIdToStagePath,omitempty"`
	// JavaScript expression to define the output filename prefix (can be constant).
	BaseFileName *string `json:"baseFileName,omitempty"`
	// Choose data compression format to apply before moving files to final destination.
	Compress *OutputFilesystemCompress `json:"compress,omitempty"`
	// Final destination for the output files
	DestPath string `json:"destPath"`
	// How often (secs) to clean-up empty directories when 'Remove Staging Dirs' is enabled.
	EmptyDirCleanupSec *int64 `json:"emptyDirCleanupSec,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`)
	FileNameSuffix *string `json:"fileNameSuffix,omitempty"`
	// Format of the output data.
	Format *OutputFilesystemDataFormat `json:"format,omitempty"`
	// Unique ID for this output
	ID *string `json:"id,omitempty"`
	// Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
	MaxFileIdleTimeSec *int64 `json:"maxFileIdleTimeSec,omitempty"`
	// Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
	MaxFileOpenTimeSec *int64 `json:"maxFileOpenTimeSec,omitempty"`
	// Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
	MaxFileSizeMB *int64 `json:"maxFileSizeMB,omitempty"`
	// Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
	MaxOpenFiles *int64 `json:"maxOpenFiles,omitempty"`
	// Whether to block or drop events when all receivers are exerting backpressure.
	OnBackpressure *OutputFilesystemBackpressureBehavior `json:"onBackpressure,omitempty"`
	// Serialization format of data pages. Note that not all reader implentations support Data page V2.
	ParquetDataPageVersion *OutputFilesystemDataPageVersion `json:"parquetDataPageVersion,omitempty"`
	// Ideal memory size for page segments. E.g., 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression. Imposes a target, not a strict limit; the final size of a row group may be larger or smaller.
	ParquetPageSize *string `json:"parquetPageSize,omitempty"`
	// Ideal memory size for row group segments. E.g., 128MB or 1GB. Affects memory use when writing. Imposes a target, not a strict limit; the final size of a row group may be larger or smaller.
	ParquetRowGroupSize *string `json:"parquetRowGroupSize,omitempty"`
	// Determines which data types are supported and how they are represented.
	ParquetVersion *OutputFilesystemParquetVersion `json:"parquetVersion,omitempty"`
	// JS expression defining how files are partitioned and organized. Default is date-based. If blank, Stream will fall back to the event's __partition field value – if present – otherwise to each location's root directory.
	PartitionExpr *string `json:"partitionExpr,omitempty"`
	// Pipeline to process data before sending out to this output.
	Pipeline *string `json:"pipeline,omitempty"`
	// Remove empty staging directories after moving files.
	RemoveEmptyDirs *bool `json:"removeEmptyDirs,omitempty"`
	// To log rows that @{product} skips due to data mismatch, first set logging to Debug, then toggle this on. Logs up to 20 unique rows.
	ShouldLogInvalidRows *bool   `json:"shouldLogInvalidRows,omitempty"`
	Spacer               *string `json:"spacer,omitempty"`
	// Filesystem location in which to buffer files before compressing and moving to final destination. Use performant, stable storage.
	StagePath *string `json:"stagePath,omitempty"`
	// Add tags for filtering and grouping in @{product}.
	Streamtags []string `json:"streamtags,omitempty"`
	// Set of fields to automatically add to events using this output. E.g.: cribl_pipe, c*. Wildcards supported.
	SystemFields []string             `json:"systemFields,omitempty"`
	Type         OutputFilesystemType `json:"type"`
}
