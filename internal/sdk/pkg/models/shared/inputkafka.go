// Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"fmt"
)

type InputKafkaConnections struct {
	// Select a Destination.
	Output string `json:"output"`
	// Select Pipeline or Pack. Optional.
	Pipeline *string `json:"pipeline,omitempty"`
}

// InputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersion - Maximum TLS version to use when connecting
type InputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersion string

const (
	InputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersionTlSv1  InputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersion = "TLSv1"
	InputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersionTlSv11 InputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersion = "TLSv1.1"
	InputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersionTlSv12 InputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersion = "TLSv1.2"
	InputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersionTlSv13 InputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersion = "TLSv1.3"
)

func (e InputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersion) ToPointer() *InputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersion {
	return &e
}

func (e *InputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersion: %v", v)
	}
}

// InputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersion - Minimum TLS version to use when connecting
type InputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersion string

const (
	InputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersionTlSv1  InputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersion = "TLSv1"
	InputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersionTlSv11 InputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersion = "TLSv1.1"
	InputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersionTlSv12 InputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersion = "TLSv1.2"
	InputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersionTlSv13 InputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersion = "TLSv1.3"
)

func (e InputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersion) ToPointer() *InputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersion {
	return &e
}

func (e *InputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersion: %v", v)
	}
}

type InputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSide struct {
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	Disabled        *bool   `json:"disabled,omitempty"`
	// Maximum TLS version to use when connecting
	MaxVersion *InputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersion `json:"maxVersion,omitempty"`
	// Minimum TLS version to use when connecting
	MinVersion *InputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersion `json:"minVersion,omitempty"`
	// Passphrase to use to decrypt private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Reject certs that are not authorized by a CA in the CA certificate path, or by another trusted CA (e.g., the system's CA). Defaults to No.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
}

type InputKafkaKafkaSchemaRegistryAuthentication struct {
	// Enable Schema Registry
	Disabled bool `json:"disabled"`
	// URL for access to the Confluent Schema Registry, i.e: http://localhost:8081
	SchemaRegistryURL *string                                                           `json:"schemaRegistryURL,omitempty"`
	TLS               *InputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSide `json:"tls,omitempty"`
}

type InputKafkaMetadata struct {
	// Field name
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

// InputKafkaPqCompression - Codec to use to compress the persisted data.
type InputKafkaPqCompression string

const (
	InputKafkaPqCompressionNone InputKafkaPqCompression = "none"
	InputKafkaPqCompressionGzip InputKafkaPqCompression = "gzip"
)

func (e InputKafkaPqCompression) ToPointer() *InputKafkaPqCompression {
	return &e
}

func (e *InputKafkaPqCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputKafkaPqCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKafkaPqCompression: %v", v)
	}
}

// InputKafkaPqMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputKafkaPqMode string

const (
	InputKafkaPqModeSmart  InputKafkaPqMode = "smart"
	InputKafkaPqModeAlways InputKafkaPqMode = "always"
)

func (e InputKafkaPqMode) ToPointer() *InputKafkaPqMode {
	return &e
}

func (e *InputKafkaPqMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputKafkaPqMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKafkaPqMode: %v", v)
	}
}

type InputKafkaPq struct {
	// The number of events to send downstream before committing that Stream has read them.
	CommitFrequency *int64 `json:"commitFrequency,omitempty"`
	// Codec to use to compress the persisted data.
	Compress *InputKafkaPqCompression `json:"compress,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk.
	MaxBufferSize *int64 `json:"maxBufferSize,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	MaxFileSize *string `json:"maxFileSize,omitempty"`
	// The maximum amount of disk space the queue is allowed to consume. Once reached, the system stops queueing and applies the fallback Queue-full behavior. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `json:"maxSize,omitempty"`
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputKafkaPqMode `json:"mode,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>.
	Path *string `json:"path,omitempty"`
}

// InputKafkaAuthenticationSASLMechanism - SASL authentication mechanism to use.
type InputKafkaAuthenticationSASLMechanism string

const (
	InputKafkaAuthenticationSASLMechanismPlain       InputKafkaAuthenticationSASLMechanism = "plain"
	InputKafkaAuthenticationSASLMechanismScramSha256 InputKafkaAuthenticationSASLMechanism = "scram-sha-256"
	InputKafkaAuthenticationSASLMechanismScramSha512 InputKafkaAuthenticationSASLMechanism = "scram-sha-512"
	InputKafkaAuthenticationSASLMechanismKerberos    InputKafkaAuthenticationSASLMechanism = "kerberos"
)

func (e InputKafkaAuthenticationSASLMechanism) ToPointer() *InputKafkaAuthenticationSASLMechanism {
	return &e
}

func (e *InputKafkaAuthenticationSASLMechanism) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "plain":
		fallthrough
	case "scram-sha-256":
		fallthrough
	case "scram-sha-512":
		fallthrough
	case "kerberos":
		*e = InputKafkaAuthenticationSASLMechanism(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKafkaAuthenticationSASLMechanism: %v", v)
	}
}

// InputKafkaAuthentication - Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
type InputKafkaAuthentication struct {
	// Enable Authentication
	Disabled bool `json:"disabled"`
	// SASL authentication mechanism to use.
	Mechanism   *InputKafkaAuthenticationSASLMechanism `json:"mechanism,omitempty"`
	XFlagprefix *string                                `json:"x-flagprefix,omitempty"`
}

// InputKafkaTLSSettingsClientSideMaximumTLSVersion - Maximum TLS version to use when connecting
type InputKafkaTLSSettingsClientSideMaximumTLSVersion string

const (
	InputKafkaTLSSettingsClientSideMaximumTLSVersionTlSv1  InputKafkaTLSSettingsClientSideMaximumTLSVersion = "TLSv1"
	InputKafkaTLSSettingsClientSideMaximumTLSVersionTlSv11 InputKafkaTLSSettingsClientSideMaximumTLSVersion = "TLSv1.1"
	InputKafkaTLSSettingsClientSideMaximumTLSVersionTlSv12 InputKafkaTLSSettingsClientSideMaximumTLSVersion = "TLSv1.2"
	InputKafkaTLSSettingsClientSideMaximumTLSVersionTlSv13 InputKafkaTLSSettingsClientSideMaximumTLSVersion = "TLSv1.3"
)

func (e InputKafkaTLSSettingsClientSideMaximumTLSVersion) ToPointer() *InputKafkaTLSSettingsClientSideMaximumTLSVersion {
	return &e
}

func (e *InputKafkaTLSSettingsClientSideMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputKafkaTLSSettingsClientSideMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKafkaTLSSettingsClientSideMaximumTLSVersion: %v", v)
	}
}

// InputKafkaTLSSettingsClientSideMinimumTLSVersion - Minimum TLS version to use when connecting
type InputKafkaTLSSettingsClientSideMinimumTLSVersion string

const (
	InputKafkaTLSSettingsClientSideMinimumTLSVersionTlSv1  InputKafkaTLSSettingsClientSideMinimumTLSVersion = "TLSv1"
	InputKafkaTLSSettingsClientSideMinimumTLSVersionTlSv11 InputKafkaTLSSettingsClientSideMinimumTLSVersion = "TLSv1.1"
	InputKafkaTLSSettingsClientSideMinimumTLSVersionTlSv12 InputKafkaTLSSettingsClientSideMinimumTLSVersion = "TLSv1.2"
	InputKafkaTLSSettingsClientSideMinimumTLSVersionTlSv13 InputKafkaTLSSettingsClientSideMinimumTLSVersion = "TLSv1.3"
)

func (e InputKafkaTLSSettingsClientSideMinimumTLSVersion) ToPointer() *InputKafkaTLSSettingsClientSideMinimumTLSVersion {
	return &e
}

func (e *InputKafkaTLSSettingsClientSideMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputKafkaTLSSettingsClientSideMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKafkaTLSSettingsClientSideMinimumTLSVersion: %v", v)
	}
}

type InputKafkaTLSSettingsClientSide struct {
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	Disabled        *bool   `json:"disabled,omitempty"`
	// Maximum TLS version to use when connecting
	MaxVersion *InputKafkaTLSSettingsClientSideMaximumTLSVersion `json:"maxVersion,omitempty"`
	// Minimum TLS version to use when connecting
	MinVersion *InputKafkaTLSSettingsClientSideMinimumTLSVersion `json:"minVersion,omitempty"`
	// Passphrase to use to decrypt private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Reject certs that are not authorized by a CA in the CA certificate path, or by another trusted CA (e.g., the system's CA). Defaults to No.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
}

type InputKafkaType string

const (
	InputKafkaTypeKafka InputKafkaType = "kafka"
)

func (e InputKafkaType) ToPointer() *InputKafkaType {
	return &e
}

func (e *InputKafkaType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "kafka":
		*e = InputKafkaType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputKafkaType: %v", v)
	}
}

type InputKafka struct {
	// Maximum time to wait for Kafka to respond to an authentication request
	AuthenticationTimeout *int64 `json:"authenticationTimeout,omitempty"`
	// How often to commit offsets. If both this and Offset commit threshold are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitInterval *int64 `json:"autoCommitInterval,omitempty"`
	// How many events are needed to trigger an offset commit. If both this and Offset commit interval are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitThreshold *int64 `json:"autoCommitThreshold,omitempty"`
	// Enter each Kafka broker you want to use. Specify hostname and port, e.g., mykafkabroker:9092, or just hostname, in which case @{product} will assign port 9092.
	Brokers []string `json:"brokers"`
	// Maximum time to wait for a connection to complete successfully
	ConnectionTimeout *int64 `json:"connectionTimeout,omitempty"`
	// Direct connections to Destinations, optionally via a Pipeline or a Pack.
	Connections []InputKafkaConnections `json:"connections,omitempty"`
	// Enable/disable this input
	Disabled *bool `json:"disabled,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Leave toggled to 'Yes' if you want the Source, upon first subscribing to a topic, to read starting with the earliest available message
	FromBeginning *bool `json:"fromBeginning,omitempty"`
	// Specifies the consumer group to which this instance belongs. Defaults to 'Cribl'.
	GroupID *string `json:"groupId,omitempty"`
	//       Expected time between heartbeats to the consumer coordinator when using Kafka's group management facilities.
	//       Value must be lower than sessionTimeout, and typically should not exceed 1/3 of the sessionTimeout value.
	//       See details [here](https://kafka.apache.org/documentation/#consumerconfigs_heartbeat.interval.ms).
	HeartbeatInterval *int64 `json:"heartbeatInterval,omitempty"`
	// Unique ID for this input
	ID                  *string                                      `json:"id,omitempty"`
	KafkaSchemaRegistry *InputKafkaKafkaSchemaRegistryAuthentication `json:"kafkaSchemaRegistry,omitempty"`
	// Maximum number of bytes that Kafka will return per fetch request. Defaults to 10485760 (10 MB).
	MaxBytes *int64 `json:"maxBytes,omitempty"`
	// Maximum amount of data that Kafka will return per partition, per fetch request. Must equal or exceed the maximum message size (maxBytesPerPartition) that Kafka is configured to allow. Otherwise, @{product} can get stuck trying to retrieve messages. Defaults to 1048576 (1 MB).
	MaxBytesPerPartition *int64 `json:"maxBytesPerPartition,omitempty"`
	// If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data.
	MaxRetries *int64 `json:"maxRetries,omitempty"`
	// Fields to add to events from this input.
	Metadata []InputKafkaMetadata `json:"metadata,omitempty"`
	// Pipeline to process data from this Source before sending it through the Routes.
	Pipeline *string       `json:"pipeline,omitempty"`
	Pq       *InputKafkaPq `json:"pq,omitempty"`
	// For details on Persistent Queues, see: [https://docs.cribl.io/stream/persistent-queues](https://docs.cribl.io/stream/persistent-queues)
	PqEnabled *bool `json:"pqEnabled,omitempty"`
	// Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backwards from the moment when credentials are set to expire.
	ReauthenticationThreshold *int64 `json:"reauthenticationThreshold,omitempty"`
	//       Maximum allowed time for each worker to join the group after a rebalance has begun.
	//       If the timeout is exceeded, the coordinator broker will remove the worker from the group.
	//       See details [here](https://kafka.apache.org/documentation/#connectconfigs_rebalance.timeout.ms).
	RebalanceTimeout *int64 `json:"rebalanceTimeout,omitempty"`
	// Maximum time to wait for Kafka to respond to a request
	RequestTimeout *int64 `json:"requestTimeout,omitempty"`
	// Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
	Sasl *InputKafkaAuthentication `json:"sasl,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	// - true
	SendToRoutes *bool `json:"sendToRoutes,omitempty"`
	//       Timeout used to detect client failures when using Kafka's group management facilities.
	//       If the client sends the broker no heartbeats before this timeout expires,
	//       the broker will remove this client from the group, and will initiate a rebalance.
	//       Value must be between the broker's configured group.min.session.timeout.ms and group.max.session.timeout.ms.
	//       See details [here](https://kafka.apache.org/documentation/#consumerconfigs_session.timeout.ms).
	SessionTimeout *int64 `json:"sessionTimeout,omitempty"`
	// Add tags for filtering and grouping in @{product}.
	Streamtags []string                         `json:"streamtags,omitempty"`
	TLS        *InputKafkaTLSSettingsClientSide `json:"tls,omitempty"`
	// Topic to subscribe to. Warning: To optimize performance, Cribl suggests subscribing each Kafka Source to only a single topic.
	Topics []string        `json:"topics"`
	Type   *InputKafkaType `json:"type,omitempty"`
}
