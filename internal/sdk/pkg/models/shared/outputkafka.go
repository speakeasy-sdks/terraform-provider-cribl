// Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"fmt"
)

// OutputKafkaAcknowledgments - Control the number of required acknowledgments.
type OutputKafkaAcknowledgments int64

const (
	OutputKafkaAcknowledgmentsOne    OutputKafkaAcknowledgments = 1
	OutputKafkaAcknowledgmentsZero   OutputKafkaAcknowledgments = 0
	OutputKafkaAcknowledgmentsMinus1 OutputKafkaAcknowledgments = -1
)

func (e OutputKafkaAcknowledgments) ToPointer() *OutputKafkaAcknowledgments {
	return &e
}

func (e *OutputKafkaAcknowledgments) UnmarshalJSON(data []byte) error {
	var v int64
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case 1:
		fallthrough
	case 0:
		fallthrough
	case -1:
		*e = OutputKafkaAcknowledgments(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputKafkaAcknowledgments: %v", v)
	}
}

// OutputKafkaCompression - Codec to use to compress the data before sending to Kafka
type OutputKafkaCompression string

const (
	OutputKafkaCompressionNone   OutputKafkaCompression = "none"
	OutputKafkaCompressionGzip   OutputKafkaCompression = "gzip"
	OutputKafkaCompressionSnappy OutputKafkaCompression = "snappy"
	OutputKafkaCompressionLz4    OutputKafkaCompression = "lz4"
)

func (e OutputKafkaCompression) ToPointer() *OutputKafkaCompression {
	return &e
}

func (e *OutputKafkaCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		fallthrough
	case "snappy":
		fallthrough
	case "lz4":
		*e = OutputKafkaCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputKafkaCompression: %v", v)
	}
}

// OutputKafkaRecordDataFormat - Format to use to serialize events before writing to Kafka.
type OutputKafkaRecordDataFormat string

const (
	OutputKafkaRecordDataFormatJSON OutputKafkaRecordDataFormat = "json"
	OutputKafkaRecordDataFormatRaw  OutputKafkaRecordDataFormat = "raw"
)

func (e OutputKafkaRecordDataFormat) ToPointer() *OutputKafkaRecordDataFormat {
	return &e
}

func (e *OutputKafkaRecordDataFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "json":
		fallthrough
	case "raw":
		*e = OutputKafkaRecordDataFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputKafkaRecordDataFormat: %v", v)
	}
}

// OutputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersion - Maximum TLS version to use when connecting
type OutputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersion string

const (
	OutputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersionTlSv1  OutputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersion = "TLSv1"
	OutputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersionTlSv11 OutputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersion = "TLSv1.1"
	OutputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersionTlSv12 OutputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersion = "TLSv1.2"
	OutputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersionTlSv13 OutputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersion = "TLSv1.3"
)

func (e OutputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersion) ToPointer() *OutputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersion {
	return &e
}

func (e *OutputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = OutputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersion: %v", v)
	}
}

// OutputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersion - Minimum TLS version to use when connecting
type OutputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersion string

const (
	OutputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersionTlSv1  OutputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersion = "TLSv1"
	OutputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersionTlSv11 OutputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersion = "TLSv1.1"
	OutputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersionTlSv12 OutputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersion = "TLSv1.2"
	OutputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersionTlSv13 OutputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersion = "TLSv1.3"
)

func (e OutputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersion) ToPointer() *OutputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersion {
	return &e
}

func (e *OutputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = OutputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersion: %v", v)
	}
}

type OutputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSide struct {
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	Disabled        *bool   `json:"disabled,omitempty"`
	// Maximum TLS version to use when connecting
	MaxVersion *OutputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersion `json:"maxVersion,omitempty"`
	// Minimum TLS version to use when connecting
	MinVersion *OutputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersion `json:"minVersion,omitempty"`
	// Passphrase to use to decrypt private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Reject certs that are not authorized by a CA in the CA certificate path, or by another trusted CA (e.g., the system's CA). Defaults to No.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
}

type OutputKafkaKafkaSchemaRegistryAuthentication struct {
	// Used when __keySchemaIdOut is not present, to transform key values, leave blank if key transformation is not required by default.
	DefaultKeySchemaID *int64 `json:"defaultKeySchemaId,omitempty"`
	// Used when __valueSchemaIdOut is not present, to transform _raw, leave blank if value transformation is not required by default.
	DefaultValueSchemaID *int64 `json:"defaultValueSchemaId,omitempty"`
	// Enable Schema Registry
	Disabled bool `json:"disabled"`
	// URL for access to the Confluent Schema Registry, i.e.: http://localhost:8081
	SchemaRegistryURL *string                                                            `json:"schemaRegistryURL,omitempty"`
	TLS               *OutputKafkaKafkaSchemaRegistryAuthenticationTLSSettingsClientSide `json:"tls,omitempty"`
}

// OutputKafkaBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputKafkaBackpressureBehavior string

const (
	OutputKafkaBackpressureBehaviorQueue OutputKafkaBackpressureBehavior = "queue"
	OutputKafkaBackpressureBehaviorDrop  OutputKafkaBackpressureBehavior = "drop"
	OutputKafkaBackpressureBehaviorBlock OutputKafkaBackpressureBehavior = "block"
)

func (e OutputKafkaBackpressureBehavior) ToPointer() *OutputKafkaBackpressureBehavior {
	return &e
}

func (e *OutputKafkaBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "queue":
		fallthrough
	case "drop":
		fallthrough
	case "block":
		*e = OutputKafkaBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputKafkaBackpressureBehavior: %v", v)
	}
}

// OutputKafkaCompression1 - Codec to use to compress the persisted data.
type OutputKafkaCompression1 string

const (
	OutputKafkaCompression1None OutputKafkaCompression1 = "none"
	OutputKafkaCompression1Gzip OutputKafkaCompression1 = "gzip"
)

func (e OutputKafkaCompression1) ToPointer() *OutputKafkaCompression1 {
	return &e
}

func (e *OutputKafkaCompression1) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputKafkaCompression1(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputKafkaCompression1: %v", v)
	}
}

type OutputKafkaPqControls struct {
}

// OutputKafkaQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputKafkaQueueFullBehavior string

const (
	OutputKafkaQueueFullBehaviorBlock OutputKafkaQueueFullBehavior = "block"
	OutputKafkaQueueFullBehaviorDrop  OutputKafkaQueueFullBehavior = "drop"
)

func (e OutputKafkaQueueFullBehavior) ToPointer() *OutputKafkaQueueFullBehavior {
	return &e
}

func (e *OutputKafkaQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputKafkaQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputKafkaQueueFullBehavior: %v", v)
	}
}

// OutputKafkaAuthenticationSASLMechanism - SASL authentication mechanism to use.
type OutputKafkaAuthenticationSASLMechanism string

const (
	OutputKafkaAuthenticationSASLMechanismPlain       OutputKafkaAuthenticationSASLMechanism = "plain"
	OutputKafkaAuthenticationSASLMechanismScramSha256 OutputKafkaAuthenticationSASLMechanism = "scram-sha-256"
	OutputKafkaAuthenticationSASLMechanismScramSha512 OutputKafkaAuthenticationSASLMechanism = "scram-sha-512"
	OutputKafkaAuthenticationSASLMechanismKerberos    OutputKafkaAuthenticationSASLMechanism = "kerberos"
)

func (e OutputKafkaAuthenticationSASLMechanism) ToPointer() *OutputKafkaAuthenticationSASLMechanism {
	return &e
}

func (e *OutputKafkaAuthenticationSASLMechanism) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "plain":
		fallthrough
	case "scram-sha-256":
		fallthrough
	case "scram-sha-512":
		fallthrough
	case "kerberos":
		*e = OutputKafkaAuthenticationSASLMechanism(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputKafkaAuthenticationSASLMechanism: %v", v)
	}
}

// OutputKafkaAuthentication - Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
type OutputKafkaAuthentication struct {
	// Enable Authentication
	Disabled bool `json:"disabled"`
	// SASL authentication mechanism to use.
	Mechanism *OutputKafkaAuthenticationSASLMechanism `json:"mechanism,omitempty"`
}

// OutputKafkaTLSSettingsClientSideMaximumTLSVersion - Maximum TLS version to use when connecting
type OutputKafkaTLSSettingsClientSideMaximumTLSVersion string

const (
	OutputKafkaTLSSettingsClientSideMaximumTLSVersionTlSv1  OutputKafkaTLSSettingsClientSideMaximumTLSVersion = "TLSv1"
	OutputKafkaTLSSettingsClientSideMaximumTLSVersionTlSv11 OutputKafkaTLSSettingsClientSideMaximumTLSVersion = "TLSv1.1"
	OutputKafkaTLSSettingsClientSideMaximumTLSVersionTlSv12 OutputKafkaTLSSettingsClientSideMaximumTLSVersion = "TLSv1.2"
	OutputKafkaTLSSettingsClientSideMaximumTLSVersionTlSv13 OutputKafkaTLSSettingsClientSideMaximumTLSVersion = "TLSv1.3"
)

func (e OutputKafkaTLSSettingsClientSideMaximumTLSVersion) ToPointer() *OutputKafkaTLSSettingsClientSideMaximumTLSVersion {
	return &e
}

func (e *OutputKafkaTLSSettingsClientSideMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = OutputKafkaTLSSettingsClientSideMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputKafkaTLSSettingsClientSideMaximumTLSVersion: %v", v)
	}
}

// OutputKafkaTLSSettingsClientSideMinimumTLSVersion - Minimum TLS version to use when connecting
type OutputKafkaTLSSettingsClientSideMinimumTLSVersion string

const (
	OutputKafkaTLSSettingsClientSideMinimumTLSVersionTlSv1  OutputKafkaTLSSettingsClientSideMinimumTLSVersion = "TLSv1"
	OutputKafkaTLSSettingsClientSideMinimumTLSVersionTlSv11 OutputKafkaTLSSettingsClientSideMinimumTLSVersion = "TLSv1.1"
	OutputKafkaTLSSettingsClientSideMinimumTLSVersionTlSv12 OutputKafkaTLSSettingsClientSideMinimumTLSVersion = "TLSv1.2"
	OutputKafkaTLSSettingsClientSideMinimumTLSVersionTlSv13 OutputKafkaTLSSettingsClientSideMinimumTLSVersion = "TLSv1.3"
)

func (e OutputKafkaTLSSettingsClientSideMinimumTLSVersion) ToPointer() *OutputKafkaTLSSettingsClientSideMinimumTLSVersion {
	return &e
}

func (e *OutputKafkaTLSSettingsClientSideMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = OutputKafkaTLSSettingsClientSideMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputKafkaTLSSettingsClientSideMinimumTLSVersion: %v", v)
	}
}

type OutputKafkaTLSSettingsClientSide struct {
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	Disabled        *bool   `json:"disabled,omitempty"`
	// Maximum TLS version to use when connecting
	MaxVersion *OutputKafkaTLSSettingsClientSideMaximumTLSVersion `json:"maxVersion,omitempty"`
	// Minimum TLS version to use when connecting
	MinVersion *OutputKafkaTLSSettingsClientSideMinimumTLSVersion `json:"minVersion,omitempty"`
	// Passphrase to use to decrypt private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Reject certs that are not authorized by a CA in the CA certificate path, or by another trusted CA (e.g., the system's CA). Defaults to No.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
}

type OutputKafkaType string

const (
	OutputKafkaTypeKafka OutputKafkaType = "kafka"
)

func (e OutputKafkaType) ToPointer() *OutputKafkaType {
	return &e
}

func (e *OutputKafkaType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "kafka":
		*e = OutputKafkaType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputKafkaType: %v", v)
	}
}

type OutputKafka struct {
	// Control the number of required acknowledgments.
	Ack *OutputKafkaAcknowledgments `json:"ack,omitempty"`
	// Maximum time to wait for Kafka to respond to an authentication request
	AuthenticationTimeout *int64 `json:"authenticationTimeout,omitempty"`
	// Enter each Kafka broker you want to use. Specify hostname and port, e.g., mykafkabroker:9092, or just hostname, in which case @{product} will assign port 9092.
	Brokers []string `json:"brokers"`
	// Codec to use to compress the data before sending to Kafka
	Compression *OutputKafkaCompression `json:"compression,omitempty"`
	// Maximum time to wait for a connection to complete successfully
	ConnectionTimeout *int64 `json:"connectionTimeout,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// The maximum number of events you want the Destination to allow in a batch before forcing a flush
	FlushEventCount *int64 `json:"flushEventCount,omitempty"`
	// The maximum amount of time you want the Destination to wait before forcing a flush. Shorter intervals tend to result in smaller batches being sent.
	FlushPeriodSec *int64 `json:"flushPeriodSec,omitempty"`
	// Format to use to serialize events before writing to Kafka.
	Format *OutputKafkaRecordDataFormat `json:"format,omitempty"`
	// Unique ID for this output
	ID                  *string                                       `json:"id,omitempty"`
	KafkaSchemaRegistry *OutputKafkaKafkaSchemaRegistryAuthentication `json:"kafkaSchemaRegistry,omitempty"`
	// Maximum size of each record batch before compression. The value must not exceed the Kafka brokers' message.max.bytes setting.
	MaxRecordSizeKB *int64 `json:"maxRecordSizeKB,omitempty"`
	// If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data.
	MaxRetries *int64 `json:"maxRetries,omitempty"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputKafkaBackpressureBehavior `json:"onBackpressure,omitempty"`
	// Pipeline to process data before sending out to this output.
	Pipeline *string `json:"pipeline,omitempty"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputKafkaCompression1 `json:"pqCompress,omitempty"`
	PqControls *OutputKafkaPqControls   `json:"pqControls,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum amount of disk space the queue is allowed to consume. Once reached, the system stops queueing and applies the fallback Queue-full behavior. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputKafkaQueueFullBehavior `json:"pqOnBackpressure,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Toggle this off to forward new events to receiver(s) before queue is flushed. Otherwise, default drain behavior is FIFO (first in, first out).
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backwards from the moment when credentials are set to expire.
	ReauthenticationThreshold *int64 `json:"reauthenticationThreshold,omitempty"`
	// Maximum time to wait for Kafka to respond to a request
	RequestTimeout *int64 `json:"requestTimeout,omitempty"`
	// Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
	Sasl *OutputKafkaAuthentication `json:"sasl,omitempty"`
	// Add tags for filtering and grouping in @{product}.
	Streamtags []string `json:"streamtags,omitempty"`
	// Set of fields to automatically add to events using this output. E.g.: cribl_pipe, c*. Wildcards supported.
	SystemFields []string                          `json:"systemFields,omitempty"`
	TLS          *OutputKafkaTLSSettingsClientSide `json:"tls,omitempty"`
	// The topic to publish events to. Can be overridden using the __topicOut field.
	Topic string           `json:"topic"`
	Type  *OutputKafkaType `json:"type,omitempty"`
}
