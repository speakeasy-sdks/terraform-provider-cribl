// Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"fmt"
)

type InputConfluentCloudConnections struct {
	// Select a Destination.
	Output string `json:"output"`
	// Select Pipeline or Pack. Optional.
	Pipeline *string `json:"pipeline,omitempty"`
}

// InputConfluentCloudKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersion - Maximum TLS version to use when connecting
type InputConfluentCloudKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersion string

const (
	InputConfluentCloudKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersionTlSv1  InputConfluentCloudKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersion = "TLSv1"
	InputConfluentCloudKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersionTlSv11 InputConfluentCloudKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersion = "TLSv1.1"
	InputConfluentCloudKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersionTlSv12 InputConfluentCloudKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersion = "TLSv1.2"
	InputConfluentCloudKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersionTlSv13 InputConfluentCloudKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersion = "TLSv1.3"
)

func (e InputConfluentCloudKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersion) ToPointer() *InputConfluentCloudKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersion {
	return &e
}

func (e *InputConfluentCloudKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputConfluentCloudKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputConfluentCloudKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersion: %v", v)
	}
}

// InputConfluentCloudKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersion - Minimum TLS version to use when connecting
type InputConfluentCloudKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersion string

const (
	InputConfluentCloudKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersionTlSv1  InputConfluentCloudKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersion = "TLSv1"
	InputConfluentCloudKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersionTlSv11 InputConfluentCloudKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersion = "TLSv1.1"
	InputConfluentCloudKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersionTlSv12 InputConfluentCloudKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersion = "TLSv1.2"
	InputConfluentCloudKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersionTlSv13 InputConfluentCloudKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersion = "TLSv1.3"
)

func (e InputConfluentCloudKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersion) ToPointer() *InputConfluentCloudKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersion {
	return &e
}

func (e *InputConfluentCloudKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputConfluentCloudKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputConfluentCloudKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersion: %v", v)
	}
}

type InputConfluentCloudKafkaSchemaRegistryAuthenticationTLSSettingsClientSide struct {
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	Disabled        *bool   `json:"disabled,omitempty"`
	// Maximum TLS version to use when connecting
	MaxVersion *InputConfluentCloudKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMaximumTLSVersion `json:"maxVersion,omitempty"`
	// Minimum TLS version to use when connecting
	MinVersion *InputConfluentCloudKafkaSchemaRegistryAuthenticationTLSSettingsClientSideMinimumTLSVersion `json:"minVersion,omitempty"`
	// Passphrase to use to decrypt private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Reject certs that are not authorized by a CA in the CA certificate path, or by another trusted CA (e.g., the system's CA). Defaults to No.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
}

type InputConfluentCloudKafkaSchemaRegistryAuthentication struct {
	// Enable Schema Registry
	Disabled bool `json:"disabled"`
	// URL for access to the Confluent Schema Registry, i.e: http://localhost:8081
	SchemaRegistryURL *string                                                                    `json:"schemaRegistryURL,omitempty"`
	TLS               *InputConfluentCloudKafkaSchemaRegistryAuthenticationTLSSettingsClientSide `json:"tls,omitempty"`
}

type InputConfluentCloudMetadata struct {
	// Field name
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

// InputConfluentCloudPqCompression - Codec to use to compress the persisted data.
type InputConfluentCloudPqCompression string

const (
	InputConfluentCloudPqCompressionNone InputConfluentCloudPqCompression = "none"
	InputConfluentCloudPqCompressionGzip InputConfluentCloudPqCompression = "gzip"
)

func (e InputConfluentCloudPqCompression) ToPointer() *InputConfluentCloudPqCompression {
	return &e
}

func (e *InputConfluentCloudPqCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputConfluentCloudPqCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputConfluentCloudPqCompression: %v", v)
	}
}

// InputConfluentCloudPqMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputConfluentCloudPqMode string

const (
	InputConfluentCloudPqModeSmart  InputConfluentCloudPqMode = "smart"
	InputConfluentCloudPqModeAlways InputConfluentCloudPqMode = "always"
)

func (e InputConfluentCloudPqMode) ToPointer() *InputConfluentCloudPqMode {
	return &e
}

func (e *InputConfluentCloudPqMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputConfluentCloudPqMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputConfluentCloudPqMode: %v", v)
	}
}

type InputConfluentCloudPq struct {
	// The number of events to send downstream before committing that Stream has read them.
	CommitFrequency *int64 `json:"commitFrequency,omitempty"`
	// Codec to use to compress the persisted data.
	Compress *InputConfluentCloudPqCompression `json:"compress,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk.
	MaxBufferSize *int64 `json:"maxBufferSize,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	MaxFileSize *string `json:"maxFileSize,omitempty"`
	// The maximum amount of disk space the queue is allowed to consume. Once reached, the system stops queueing and applies the fallback Queue-full behavior. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `json:"maxSize,omitempty"`
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputConfluentCloudPqMode `json:"mode,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>.
	Path *string `json:"path,omitempty"`
}

// InputConfluentCloudAuthenticationSASLMechanism - SASL authentication mechanism to use.
type InputConfluentCloudAuthenticationSASLMechanism string

const (
	InputConfluentCloudAuthenticationSASLMechanismPlain       InputConfluentCloudAuthenticationSASLMechanism = "plain"
	InputConfluentCloudAuthenticationSASLMechanismScramSha256 InputConfluentCloudAuthenticationSASLMechanism = "scram-sha-256"
	InputConfluentCloudAuthenticationSASLMechanismScramSha512 InputConfluentCloudAuthenticationSASLMechanism = "scram-sha-512"
	InputConfluentCloudAuthenticationSASLMechanismKerberos    InputConfluentCloudAuthenticationSASLMechanism = "kerberos"
)

func (e InputConfluentCloudAuthenticationSASLMechanism) ToPointer() *InputConfluentCloudAuthenticationSASLMechanism {
	return &e
}

func (e *InputConfluentCloudAuthenticationSASLMechanism) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "plain":
		fallthrough
	case "scram-sha-256":
		fallthrough
	case "scram-sha-512":
		fallthrough
	case "kerberos":
		*e = InputConfluentCloudAuthenticationSASLMechanism(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputConfluentCloudAuthenticationSASLMechanism: %v", v)
	}
}

// InputConfluentCloudAuthentication - Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
type InputConfluentCloudAuthentication struct {
	// Enable Authentication
	Disabled bool `json:"disabled"`
	// SASL authentication mechanism to use.
	Mechanism   *InputConfluentCloudAuthenticationSASLMechanism `json:"mechanism,omitempty"`
	XFlagprefix *string                                         `json:"x-flagprefix,omitempty"`
}

// InputConfluentCloudTLSSettingsClientSideMaximumTLSVersion - Maximum TLS version to use when connecting
type InputConfluentCloudTLSSettingsClientSideMaximumTLSVersion string

const (
	InputConfluentCloudTLSSettingsClientSideMaximumTLSVersionTlSv1  InputConfluentCloudTLSSettingsClientSideMaximumTLSVersion = "TLSv1"
	InputConfluentCloudTLSSettingsClientSideMaximumTLSVersionTlSv11 InputConfluentCloudTLSSettingsClientSideMaximumTLSVersion = "TLSv1.1"
	InputConfluentCloudTLSSettingsClientSideMaximumTLSVersionTlSv12 InputConfluentCloudTLSSettingsClientSideMaximumTLSVersion = "TLSv1.2"
	InputConfluentCloudTLSSettingsClientSideMaximumTLSVersionTlSv13 InputConfluentCloudTLSSettingsClientSideMaximumTLSVersion = "TLSv1.3"
)

func (e InputConfluentCloudTLSSettingsClientSideMaximumTLSVersion) ToPointer() *InputConfluentCloudTLSSettingsClientSideMaximumTLSVersion {
	return &e
}

func (e *InputConfluentCloudTLSSettingsClientSideMaximumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputConfluentCloudTLSSettingsClientSideMaximumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputConfluentCloudTLSSettingsClientSideMaximumTLSVersion: %v", v)
	}
}

// InputConfluentCloudTLSSettingsClientSideMinimumTLSVersion - Minimum TLS version to use when connecting
type InputConfluentCloudTLSSettingsClientSideMinimumTLSVersion string

const (
	InputConfluentCloudTLSSettingsClientSideMinimumTLSVersionTlSv1  InputConfluentCloudTLSSettingsClientSideMinimumTLSVersion = "TLSv1"
	InputConfluentCloudTLSSettingsClientSideMinimumTLSVersionTlSv11 InputConfluentCloudTLSSettingsClientSideMinimumTLSVersion = "TLSv1.1"
	InputConfluentCloudTLSSettingsClientSideMinimumTLSVersionTlSv12 InputConfluentCloudTLSSettingsClientSideMinimumTLSVersion = "TLSv1.2"
	InputConfluentCloudTLSSettingsClientSideMinimumTLSVersionTlSv13 InputConfluentCloudTLSSettingsClientSideMinimumTLSVersion = "TLSv1.3"
)

func (e InputConfluentCloudTLSSettingsClientSideMinimumTLSVersion) ToPointer() *InputConfluentCloudTLSSettingsClientSideMinimumTLSVersion {
	return &e
}

func (e *InputConfluentCloudTLSSettingsClientSideMinimumTLSVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TLSv1":
		fallthrough
	case "TLSv1.1":
		fallthrough
	case "TLSv1.2":
		fallthrough
	case "TLSv1.3":
		*e = InputConfluentCloudTLSSettingsClientSideMinimumTLSVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputConfluentCloudTLSSettingsClientSideMinimumTLSVersion: %v", v)
	}
}

type InputConfluentCloudTLSSettingsClientSide struct {
	// Path on client in which to find CA certificates to verify the server's cert. PEM format. Can reference $ENV_VARS.
	CaPath *string `json:"caPath,omitempty"`
	// Path on client in which to find certificates to use. PEM format. Can reference $ENV_VARS.
	CertPath *string `json:"certPath,omitempty"`
	// The name of the predefined certificate.
	CertificateName *string `json:"certificateName,omitempty"`
	Disabled        *bool   `json:"disabled,omitempty"`
	// Maximum TLS version to use when connecting
	MaxVersion *InputConfluentCloudTLSSettingsClientSideMaximumTLSVersion `json:"maxVersion,omitempty"`
	// Minimum TLS version to use when connecting
	MinVersion *InputConfluentCloudTLSSettingsClientSideMinimumTLSVersion `json:"minVersion,omitempty"`
	// Passphrase to use to decrypt private key.
	Passphrase *string `json:"passphrase,omitempty"`
	// Path on client in which to find the private key to use. PEM format. Can reference $ENV_VARS.
	PrivKeyPath *string `json:"privKeyPath,omitempty"`
	// Reject certs that are not authorized by a CA in the CA certificate path, or by another trusted CA (e.g., the system's CA). Defaults to No.
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Server name for the SNI (Server Name Indication) TLS extension. It must be a host name, and not an IP address.
	Servername *string `json:"servername,omitempty"`
}

type InputConfluentCloudType string

const (
	InputConfluentCloudTypeConfluentCloud InputConfluentCloudType = "confluent_cloud"
)

func (e InputConfluentCloudType) ToPointer() *InputConfluentCloudType {
	return &e
}

func (e *InputConfluentCloudType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "confluent_cloud":
		*e = InputConfluentCloudType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputConfluentCloudType: %v", v)
	}
}

type InputConfluentCloud struct {
	// Maximum time to wait for Kafka to respond to an authentication request
	AuthenticationTimeout *int64 `json:"authenticationTimeout,omitempty"`
	// How often to commit offsets. If both this and Offset commit threshold are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitInterval *int64 `json:"autoCommitInterval,omitempty"`
	// How many events are needed to trigger an offset commit. If both this and Offset commit interval are set, @{product} commits offsets when either condition is met. If both are empty, @{product} commits offsets after each batch.
	AutoCommitThreshold *int64 `json:"autoCommitThreshold,omitempty"`
	// List of Confluent Cloud brokers to use, eg. yourAccount.confluent.cloud:9092
	Brokers []string `json:"brokers"`
	// Maximum time to wait for a connection to complete successfully
	ConnectionTimeout *int64 `json:"connectionTimeout,omitempty"`
	// Direct connections to Destinations, optionally via a Pipeline or a Pack.
	Connections []InputConfluentCloudConnections `json:"connections,omitempty"`
	// Enable/disable this input
	Disabled *bool `json:"disabled,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Leave toggled to 'Yes' if you want the Source, upon first subscribing to a topic, to read starting with the earliest available message
	FromBeginning *bool `json:"fromBeginning,omitempty"`
	// Specifies the consumer group to which this instance belongs. Defaults to 'Cribl'.
	GroupID *string `json:"groupId,omitempty"`
	//       Expected time between heartbeats to the consumer coordinator when using Kafka's group management facilities.
	//       Value must be lower than sessionTimeout, and typically should not exceed 1/3 of the sessionTimeout value.
	//       See details [here](https://kafka.apache.org/documentation/#consumerconfigs_heartbeat.interval.ms).
	HeartbeatInterval *int64 `json:"heartbeatInterval,omitempty"`
	// Unique ID for this input
	ID                  *string                                               `json:"id,omitempty"`
	KafkaSchemaRegistry *InputConfluentCloudKafkaSchemaRegistryAuthentication `json:"kafkaSchemaRegistry,omitempty"`
	// Maximum number of bytes that Kafka will return per fetch request. Defaults to 10485760 (10 MB).
	MaxBytes *int64 `json:"maxBytes,omitempty"`
	// Maximum amount of data that Kafka will return per partition, per fetch request. Must equal or exceed the maximum message size (maxBytesPerPartition) that Kafka is configured to allow. Otherwise, @{product} can get stuck trying to retrieve messages. Defaults to 1048576 (1 MB).
	MaxBytesPerPartition *int64 `json:"maxBytesPerPartition,omitempty"`
	// If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data.
	MaxRetries *int64 `json:"maxRetries,omitempty"`
	// Fields to add to events from this input.
	Metadata []InputConfluentCloudMetadata `json:"metadata,omitempty"`
	// Pipeline to process data from this Source before sending it through the Routes.
	Pipeline *string                `json:"pipeline,omitempty"`
	Pq       *InputConfluentCloudPq `json:"pq,omitempty"`
	// For details on Persistent Queues, see: [https://docs.cribl.io/stream/persistent-queues](https://docs.cribl.io/stream/persistent-queues)
	PqEnabled *bool `json:"pqEnabled,omitempty"`
	// Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backwards from the moment when credentials are set to expire.
	ReauthenticationThreshold *int64 `json:"reauthenticationThreshold,omitempty"`
	//       Maximum allowed time for each worker to join the group after a rebalance has begun.
	//       If the timeout is exceeded, the coordinator broker will remove the worker from the group.
	//       See details [here](https://kafka.apache.org/documentation/#connectconfigs_rebalance.timeout.ms).
	RebalanceTimeout *int64 `json:"rebalanceTimeout,omitempty"`
	// Maximum time to wait for Kafka to respond to a request
	RequestTimeout *int64 `json:"requestTimeout,omitempty"`
	// Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
	Sasl *InputConfluentCloudAuthentication `json:"sasl,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitempty"`
	//       Timeout used to detect client failures when using Kafka's group management facilities.
	//       If the client sends the broker no heartbeats before this timeout expires,
	//       the broker will remove this client from the group, and will initiate a rebalance.
	//       Value must be between the broker's configured group.min.session.timeout.ms and group.max.session.timeout.ms.
	//       See details [here](https://kafka.apache.org/documentation/#consumerconfigs_session.timeout.ms).
	SessionTimeout *int64 `json:"sessionTimeout,omitempty"`
	// Add tags for filtering and grouping in @{product}.
	Streamtags []string                                  `json:"streamtags,omitempty"`
	TLS        *InputConfluentCloudTLSSettingsClientSide `json:"tls,omitempty"`
	// Topic to subscribe to. Warning: To optimize performance, Cribl suggests subscribing each Kafka Source to only a single topic.
	Topics []string                 `json:"topics"`
	Type   *InputConfluentCloudType `json:"type,omitempty"`
}
