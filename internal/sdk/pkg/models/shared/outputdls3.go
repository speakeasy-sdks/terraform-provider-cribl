// Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"fmt"
)

// OutputDlS3AuthenticationMethod - AWS authentication method. Choose Auto to use IAM roles.
type OutputDlS3AuthenticationMethod string

const (
	OutputDlS3AuthenticationMethodSecret OutputDlS3AuthenticationMethod = "secret"
	OutputDlS3AuthenticationMethodManual OutputDlS3AuthenticationMethod = "manual"
)

func (e OutputDlS3AuthenticationMethod) ToPointer() *OutputDlS3AuthenticationMethod {
	return &e
}

func (e *OutputDlS3AuthenticationMethod) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "secret":
		fallthrough
	case "manual":
		*e = OutputDlS3AuthenticationMethod(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDlS3AuthenticationMethod: %v", v)
	}
}

// OutputDlS3Compress - Choose data compression format to apply before moving files to final destination.
type OutputDlS3Compress string

const (
	OutputDlS3CompressNone OutputDlS3Compress = "none"
	OutputDlS3CompressGzip OutputDlS3Compress = "gzip"
)

func (e OutputDlS3Compress) ToPointer() *OutputDlS3Compress {
	return &e
}

func (e *OutputDlS3Compress) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputDlS3Compress(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDlS3Compress: %v", v)
	}
}

// OutputDlS3DataFormat - Format of the output data.
type OutputDlS3DataFormat string

const (
	OutputDlS3DataFormatParquet OutputDlS3DataFormat = "parquet"
	OutputDlS3DataFormatRaw     OutputDlS3DataFormat = "raw"
	OutputDlS3DataFormatJSON    OutputDlS3DataFormat = "json"
)

func (e OutputDlS3DataFormat) ToPointer() *OutputDlS3DataFormat {
	return &e
}

func (e *OutputDlS3DataFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "parquet":
		fallthrough
	case "raw":
		fallthrough
	case "json":
		*e = OutputDlS3DataFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDlS3DataFormat: %v", v)
	}
}

// OutputDlS3ObjectACL - Object ACL to assign to uploaded objects.
type OutputDlS3ObjectACL string

const (
	OutputDlS3ObjectACLPrivate                OutputDlS3ObjectACL = "private"
	OutputDlS3ObjectACLPublicRead             OutputDlS3ObjectACL = "public-read"
	OutputDlS3ObjectACLPublicReadWrite        OutputDlS3ObjectACL = "public-read-write"
	OutputDlS3ObjectACLAuthenticatedRead      OutputDlS3ObjectACL = "authenticated-read"
	OutputDlS3ObjectACLAwsExecRead            OutputDlS3ObjectACL = "aws-exec-read"
	OutputDlS3ObjectACLBucketOwnerRead        OutputDlS3ObjectACL = "bucket-owner-read"
	OutputDlS3ObjectACLBucketOwnerFullControl OutputDlS3ObjectACL = "bucket-owner-full-control"
)

func (e OutputDlS3ObjectACL) ToPointer() *OutputDlS3ObjectACL {
	return &e
}

func (e *OutputDlS3ObjectACL) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "private":
		fallthrough
	case "public-read":
		fallthrough
	case "public-read-write":
		fallthrough
	case "authenticated-read":
		fallthrough
	case "aws-exec-read":
		fallthrough
	case "bucket-owner-read":
		fallthrough
	case "bucket-owner-full-control":
		*e = OutputDlS3ObjectACL(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDlS3ObjectACL: %v", v)
	}
}

// OutputDlS3BackpressureBehavior - Whether to block or drop events when all receivers are exerting backpressure.
type OutputDlS3BackpressureBehavior string

const (
	OutputDlS3BackpressureBehaviorBlock OutputDlS3BackpressureBehavior = "block"
	OutputDlS3BackpressureBehaviorDrop  OutputDlS3BackpressureBehavior = "drop"
)

func (e OutputDlS3BackpressureBehavior) ToPointer() *OutputDlS3BackpressureBehavior {
	return &e
}

func (e *OutputDlS3BackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputDlS3BackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDlS3BackpressureBehavior: %v", v)
	}
}

// OutputDlS3DataPageVersion - Serialization format of data pages. Note that not all reader implentations support Data page V2.
type OutputDlS3DataPageVersion string

const (
	OutputDlS3DataPageVersionDataPageV1 OutputDlS3DataPageVersion = "DATA_PAGE_V1"
	OutputDlS3DataPageVersionDataPageV2 OutputDlS3DataPageVersion = "DATA_PAGE_V2"
)

func (e OutputDlS3DataPageVersion) ToPointer() *OutputDlS3DataPageVersion {
	return &e
}

func (e *OutputDlS3DataPageVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "DATA_PAGE_V1":
		fallthrough
	case "DATA_PAGE_V2":
		*e = OutputDlS3DataPageVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDlS3DataPageVersion: %v", v)
	}
}

// OutputDlS3ParquetVersion - Determines which data types are supported and how they are represented.
type OutputDlS3ParquetVersion string

const (
	OutputDlS3ParquetVersionParquet10 OutputDlS3ParquetVersion = "PARQUET_1_0"
	OutputDlS3ParquetVersionParquet24 OutputDlS3ParquetVersion = "PARQUET_2_4"
	OutputDlS3ParquetVersionParquet26 OutputDlS3ParquetVersion = "PARQUET_2_6"
)

func (e OutputDlS3ParquetVersion) ToPointer() *OutputDlS3ParquetVersion {
	return &e
}

func (e *OutputDlS3ParquetVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "PARQUET_1_0":
		fallthrough
	case "PARQUET_2_4":
		fallthrough
	case "PARQUET_2_6":
		*e = OutputDlS3ParquetVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDlS3ParquetVersion: %v", v)
	}
}

// OutputDlS3Region - Region where the S3 bucket is located.
type OutputDlS3Region string

const (
	OutputDlS3RegionUsEast1      OutputDlS3Region = "us-east-1"
	OutputDlS3RegionUsEast2      OutputDlS3Region = "us-east-2"
	OutputDlS3RegionUsWest1      OutputDlS3Region = "us-west-1"
	OutputDlS3RegionUsWest2      OutputDlS3Region = "us-west-2"
	OutputDlS3RegionAfSouth1     OutputDlS3Region = "af-south-1"
	OutputDlS3RegionCaCentral1   OutputDlS3Region = "ca-central-1"
	OutputDlS3RegionEuWest1      OutputDlS3Region = "eu-west-1"
	OutputDlS3RegionEuCentral1   OutputDlS3Region = "eu-central-1"
	OutputDlS3RegionEuWest2      OutputDlS3Region = "eu-west-2"
	OutputDlS3RegionEuSouth1     OutputDlS3Region = "eu-south-1"
	OutputDlS3RegionEuWest3      OutputDlS3Region = "eu-west-3"
	OutputDlS3RegionEuNorth1     OutputDlS3Region = "eu-north-1"
	OutputDlS3RegionApEast1      OutputDlS3Region = "ap-east-1"
	OutputDlS3RegionApNortheast1 OutputDlS3Region = "ap-northeast-1"
	OutputDlS3RegionApNortheast2 OutputDlS3Region = "ap-northeast-2"
	OutputDlS3RegionApSoutheast1 OutputDlS3Region = "ap-southeast-1"
	OutputDlS3RegionApSoutheast2 OutputDlS3Region = "ap-southeast-2"
	OutputDlS3RegionApSouth1     OutputDlS3Region = "ap-south-1"
	OutputDlS3RegionMeSouth1     OutputDlS3Region = "me-south-1"
	OutputDlS3RegionSaEast1      OutputDlS3Region = "sa-east-1"
	OutputDlS3RegionUsGovEast1   OutputDlS3Region = "us-gov-east-1"
	OutputDlS3RegionUsGovWest1   OutputDlS3Region = "us-gov-west-1"
)

func (e OutputDlS3Region) ToPointer() *OutputDlS3Region {
	return &e
}

func (e *OutputDlS3Region) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "us-east-1":
		fallthrough
	case "us-east-2":
		fallthrough
	case "us-west-1":
		fallthrough
	case "us-west-2":
		fallthrough
	case "af-south-1":
		fallthrough
	case "ca-central-1":
		fallthrough
	case "eu-west-1":
		fallthrough
	case "eu-central-1":
		fallthrough
	case "eu-west-2":
		fallthrough
	case "eu-south-1":
		fallthrough
	case "eu-west-3":
		fallthrough
	case "eu-north-1":
		fallthrough
	case "ap-east-1":
		fallthrough
	case "ap-northeast-1":
		fallthrough
	case "ap-northeast-2":
		fallthrough
	case "ap-southeast-1":
		fallthrough
	case "ap-southeast-2":
		fallthrough
	case "ap-south-1":
		fallthrough
	case "me-south-1":
		fallthrough
	case "sa-east-1":
		fallthrough
	case "us-gov-east-1":
		fallthrough
	case "us-gov-west-1":
		*e = OutputDlS3Region(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDlS3Region: %v", v)
	}
}

// OutputDlS3ServerSideEncryption - Server-side encryption for uploaded objects.
type OutputDlS3ServerSideEncryption string

const (
	OutputDlS3ServerSideEncryptionAwsKms OutputDlS3ServerSideEncryption = "aws:kms"
)

func (e OutputDlS3ServerSideEncryption) ToPointer() *OutputDlS3ServerSideEncryption {
	return &e
}

func (e *OutputDlS3ServerSideEncryption) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "aws:kms":
		*e = OutputDlS3ServerSideEncryption(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDlS3ServerSideEncryption: %v", v)
	}
}

// OutputDlS3SignatureVersion - Signature version to use for signing S3 requests.
type OutputDlS3SignatureVersion string

const (
	OutputDlS3SignatureVersionV2 OutputDlS3SignatureVersion = "v2"
	OutputDlS3SignatureVersionV4 OutputDlS3SignatureVersion = "v4"
)

func (e OutputDlS3SignatureVersion) ToPointer() *OutputDlS3SignatureVersion {
	return &e
}

func (e *OutputDlS3SignatureVersion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "v2":
		fallthrough
	case "v4":
		*e = OutputDlS3SignatureVersion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDlS3SignatureVersion: %v", v)
	}
}

// OutputDlS3StorageClass - Storage class to select for uploaded objects.
type OutputDlS3StorageClass string

const (
	OutputDlS3StorageClassStandard           OutputDlS3StorageClass = "STANDARD"
	OutputDlS3StorageClassReducedRedundancy  OutputDlS3StorageClass = "REDUCED_REDUNDANCY"
	OutputDlS3StorageClassStandardIa         OutputDlS3StorageClass = "STANDARD_IA"
	OutputDlS3StorageClassOnezoneIa          OutputDlS3StorageClass = "ONEZONE_IA"
	OutputDlS3StorageClassIntelligentTiering OutputDlS3StorageClass = "INTELLIGENT_TIERING"
	OutputDlS3StorageClassGlacier            OutputDlS3StorageClass = "GLACIER"
	OutputDlS3StorageClassDeepArchive        OutputDlS3StorageClass = "DEEP_ARCHIVE"
)

func (e OutputDlS3StorageClass) ToPointer() *OutputDlS3StorageClass {
	return &e
}

func (e *OutputDlS3StorageClass) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "STANDARD":
		fallthrough
	case "REDUCED_REDUNDANCY":
		fallthrough
	case "STANDARD_IA":
		fallthrough
	case "ONEZONE_IA":
		fallthrough
	case "INTELLIGENT_TIERING":
		fallthrough
	case "GLACIER":
		fallthrough
	case "DEEP_ARCHIVE":
		*e = OutputDlS3StorageClass(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDlS3StorageClass: %v", v)
	}
}

type OutputDlS3Type string

const (
	OutputDlS3TypeDlS3 OutputDlS3Type = "dl_s3"
)

func (e OutputDlS3Type) ToPointer() *OutputDlS3Type {
	return &e
}

func (e *OutputDlS3Type) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "dl_s3":
		*e = OutputDlS3Type(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputDlS3Type: %v", v)
	}
}

type OutputDlS3 struct {
	// Append output's ID to staging location.
	AddIDToStagePath *bool `json:"addIdToStagePath,omitempty"`
	// Amazon Resource Name (ARN) of the role to assume
	AssumeRoleArn *string `json:"assumeRoleArn,omitempty"`
	// External ID to use when assuming role
	AssumeRoleExternalID *string `json:"assumeRoleExternalId,omitempty"`
	// Access key. This value can be a constant or a JavaScript expression(e.g., `${C.env.SOME_ACCESS_KEY}`).
	AwsAPIKey *string `json:"awsApiKey,omitempty"`
	// AWS authentication method. Choose Auto to use IAM roles.
	AwsAuthenticationMethod *OutputDlS3AuthenticationMethod `json:"awsAuthenticationMethod,omitempty"`
	// Select (or create) a stored secret that references your access key and secret key.
	AwsSecret *string `json:"awsSecret,omitempty"`
	// Secret key. This value can be a constant or a JavaScript expression(e.g., `${C.env.SOME_SECRET}`).
	AwsSecretKey *string `json:"awsSecretKey,omitempty"`
	// JavaScript expression to define the output filename prefix (can be constant).
	BaseFileName *string `json:"baseFileName,omitempty"`
	// Name of the destination S3 bucket. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. E.g., referencing a Global Variable: `myBucket-${C.vars.myVar}`.
	Bucket string `json:"bucket"`
	// Choose data compression format to apply before moving files to final destination.
	Compress *OutputDlS3Compress `json:"compress,omitempty"`
	// Prefix to append to files before uploading. Must be a JavaScript expression (which can evaluate to a constant value), enclosed in quotes or backticks. Can be evaluated only at init time. E.g., referencing a Global Variable: `myKeyPrefix-${C.vars.myVar}`.
	DestPath *string `json:"destPath,omitempty"`
	// How often (secs) to clean-up empty directories when 'Remove Staging Dirs' is enabled.
	EmptyDirCleanupSec *int64 `json:"emptyDirCleanupSec,omitempty"`
	// Use Assume Role credentials to access S3
	EnableAssumeRole *bool `json:"enableAssumeRole,omitempty"`
	// S3 service endpoint. If empty, defaults to AWS' Region-specific endpoint. Otherwise, it must point to S3-compatible endpoint.
	Endpoint *string `json:"endpoint,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// JavaScript expression to define the output filename suffix (can be constant).  The `__format` variable refers to the value of the `Data format` field (`json` or `raw`).  The `__compression` field refers to the kind of compression being used (`none` or `gzip`)
	FileNameSuffix *string `json:"fileNameSuffix,omitempty"`
	// Format of the output data.
	Format *OutputDlS3DataFormat `json:"format,omitempty"`
	// Unique ID for this output
	ID *string `json:"id,omitempty"`
	// ID or ARN of the KMS customer-managed key to use for encryption
	KmsKeyID *string `json:"kmsKeyId,omitempty"`
	// Maximum number of parts to upload in parallel per file. Minimum part size is 5MB.
	MaxConcurrentFileParts *int64 `json:"maxConcurrentFileParts,omitempty"`
	// Maximum amount of time to keep inactive files open. Files open for longer than this will be closed and moved to final output location.
	MaxFileIdleTimeSec *int64 `json:"maxFileIdleTimeSec,omitempty"`
	// Maximum amount of time to write to a file. Files open for longer than this will be closed and moved to final output location.
	MaxFileOpenTimeSec *int64 `json:"maxFileOpenTimeSec,omitempty"`
	// Maximum uncompressed output file size. Files of this size will be closed and moved to final output location.
	MaxFileSizeMB *int64 `json:"maxFileSizeMB,omitempty"`
	// Maximum number of files to keep open concurrently. When exceeded, @{product} will close the oldest open files and move them to the final output location.
	MaxOpenFiles *int64 `json:"maxOpenFiles,omitempty"`
	// Object ACL to assign to uploaded objects.
	ObjectACL *OutputDlS3ObjectACL `json:"objectACL,omitempty"`
	// Whether to block or drop events when all receivers are exerting backpressure.
	OnBackpressure *OutputDlS3BackpressureBehavior `json:"onBackpressure,omitempty"`
	// Serialization format of data pages. Note that not all reader implentations support Data page V2.
	ParquetDataPageVersion *OutputDlS3DataPageVersion `json:"parquetDataPageVersion,omitempty"`
	// Ideal memory size for page segments. E.g., 1MB or 128MB. Generally, lower values improve reading speed, while higher values improve compression. Imposes a target, not a strict limit; the final size of a row group may be larger or smaller.
	ParquetPageSize *string `json:"parquetPageSize,omitempty"`
	// Ideal memory size for row group segments. E.g., 128MB or 1GB. Affects memory use when writing. Imposes a target, not a strict limit; the final size of a row group may be larger or smaller.
	ParquetRowGroupSize *string `json:"parquetRowGroupSize,omitempty"`
	// Determines which data types are supported and how they are represented.
	ParquetVersion *OutputDlS3ParquetVersion `json:"parquetVersion,omitempty"`
	// JS expression defining how files are partitioned and organized. Default is date-based. If blank, Stream will fall back to the event's __partition field value – if present – otherwise to each location's root directory.
	PartitionExpr *string `json:"partitionExpr,omitempty"`
	// List of fields to partition the path by, in addition to time, which is included automatically. The effective partition will be YYYY/MM/DD/HH/<list/of/fields>.
	PartitioningFields []string `json:"partitioningFields,omitempty"`
	// Pipeline to process data before sending out to this output.
	Pipeline *string `json:"pipeline,omitempty"`
	// Region where the S3 bucket is located.
	Region *OutputDlS3Region `json:"region,omitempty"`
	// Whether to reject certificates that cannot be verified against a valid CA (e.g., self-signed certificates).
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
	// Remove empty staging directories after moving files.
	RemoveEmptyDirs *bool `json:"removeEmptyDirs,omitempty"`
	// Whether to reuse connections between requests, which can improve performance.
	ReuseConnections *bool `json:"reuseConnections,omitempty"`
	// Server-side encryption for uploaded objects.
	ServerSideEncryption *OutputDlS3ServerSideEncryption `json:"serverSideEncryption,omitempty"`
	// To log rows that @{product} skips due to data mismatch, first set logging to Debug, then toggle this on. Logs up to 20 unique rows.
	ShouldLogInvalidRows *bool `json:"shouldLogInvalidRows,omitempty"`
	// Signature version to use for signing S3 requests.
	SignatureVersion *OutputDlS3SignatureVersion `json:"signatureVersion,omitempty"`
	Spacer           *string                     `json:"spacer,omitempty"`
	// Filesystem location in which to buffer files, before compressing and moving to final destination. Use performant stable storage.
	StagePath string `json:"stagePath"`
	// Storage class to select for uploaded objects.
	StorageClass *OutputDlS3StorageClass `json:"storageClass,omitempty"`
	// Add tags for filtering and grouping in @{product}.
	Streamtags []string `json:"streamtags,omitempty"`
	// Set of fields to automatically add to events using this output. E.g.: cribl_pipe, c*. Wildcards supported.
	SystemFields []string        `json:"systemFields,omitempty"`
	Type         *OutputDlS3Type `json:"type,omitempty"`
}
