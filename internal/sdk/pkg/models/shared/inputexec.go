// Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"fmt"
)

type InputExecConnections struct {
	// Select a Destination.
	Output string `json:"output"`
	// Select Pipeline or Pack. Optional.
	Pipeline *string `json:"pipeline,omitempty"`
}

type InputExecMetadata struct {
	// Field name
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

type InputExecOptionalFieldsInGeneralSection string

const (
	InputExecOptionalFieldsInGeneralSectionScheduleType InputExecOptionalFieldsInGeneralSection = "scheduleType"
)

func (e InputExecOptionalFieldsInGeneralSection) ToPointer() *InputExecOptionalFieldsInGeneralSection {
	return &e
}

func (e *InputExecOptionalFieldsInGeneralSection) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "scheduleType":
		*e = InputExecOptionalFieldsInGeneralSection(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputExecOptionalFieldsInGeneralSection: %v", v)
	}
}

// InputExecPqCompression - Codec to use to compress the persisted data.
type InputExecPqCompression string

const (
	InputExecPqCompressionNone InputExecPqCompression = "none"
	InputExecPqCompressionGzip InputExecPqCompression = "gzip"
)

func (e InputExecPqCompression) ToPointer() *InputExecPqCompression {
	return &e
}

func (e *InputExecPqCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputExecPqCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputExecPqCompression: %v", v)
	}
}

// InputExecPqMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputExecPqMode string

const (
	InputExecPqModeSmart  InputExecPqMode = "smart"
	InputExecPqModeAlways InputExecPqMode = "always"
)

func (e InputExecPqMode) ToPointer() *InputExecPqMode {
	return &e
}

func (e *InputExecPqMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputExecPqMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputExecPqMode: %v", v)
	}
}

type InputExecPq struct {
	// The number of events to send downstream before committing that Stream has read them.
	CommitFrequency *int64 `json:"commitFrequency,omitempty"`
	// Codec to use to compress the persisted data.
	Compress *InputExecPqCompression `json:"compress,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk.
	MaxBufferSize *int64 `json:"maxBufferSize,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	MaxFileSize *string `json:"maxFileSize,omitempty"`
	// The maximum amount of disk space the queue is allowed to consume. Once reached, the system stops queueing and applies the fallback Queue-full behavior. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `json:"maxSize,omitempty"`
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputExecPqMode `json:"mode,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>.
	Path *string `json:"path,omitempty"`
}

// InputExecScheduleType - Select a schedule type; either an interval (in seconds) or a cron-style schedule.
type InputExecScheduleType string

const (
	InputExecScheduleTypeCronSchedule InputExecScheduleType = "cronSchedule"
)

func (e InputExecScheduleType) ToPointer() *InputExecScheduleType {
	return &e
}

func (e *InputExecScheduleType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "cronSchedule":
		*e = InputExecScheduleType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputExecScheduleType: %v", v)
	}
}

type InputExecInputType string

const (
	InputExecInputTypeSplunk            InputExecInputType = "splunk"
	InputExecInputTypeSplunkHec         InputExecInputType = "splunk_hec"
	InputExecInputTypeSyslog            InputExecInputType = "syslog"
	InputExecInputTypeTcpjson           InputExecInputType = "tcpjson"
	InputExecInputTypeGrafana           InputExecInputType = "grafana"
	InputExecInputTypeLoki              InputExecInputType = "loki"
	InputExecInputTypeHTTP              InputExecInputType = "http"
	InputExecInputTypeHTTPRaw           InputExecInputType = "http_raw"
	InputExecInputTypeFirehose          InputExecInputType = "firehose"
	InputExecInputTypeElastic           InputExecInputType = "elastic"
	InputExecInputTypeKafka             InputExecInputType = "kafka"
	InputExecInputTypeConfluentCloud    InputExecInputType = "confluent_cloud"
	InputExecInputTypeMsk               InputExecInputType = "msk"
	InputExecInputTypeKinesis           InputExecInputType = "kinesis"
	InputExecInputTypeEventhub          InputExecInputType = "eventhub"
	InputExecInputTypeAzureBlob         InputExecInputType = "azure_blob"
	InputExecInputTypeMetrics           InputExecInputType = "metrics"
	InputExecInputTypeSqs               InputExecInputType = "sqs"
	InputExecInputTypeS3                InputExecInputType = "s3"
	InputExecInputTypeSnmp              InputExecInputType = "snmp"
	InputExecInputTypeCrowdstrike       InputExecInputType = "crowdstrike"
	InputExecInputTypeTCP               InputExecInputType = "tcp"
	InputExecInputTypeRawUDP            InputExecInputType = "raw_udp"
	InputExecInputTypeOffice365Service  InputExecInputType = "office365_service"
	InputExecInputTypeOffice365Mgmt     InputExecInputType = "office365_mgmt"
	InputExecInputTypeOffice365MsgTrace InputExecInputType = "office365_msg_trace"
	InputExecInputTypePrometheus        InputExecInputType = "prometheus"
	InputExecInputTypeEdgePrometheus    InputExecInputType = "edge_prometheus"
	InputExecInputTypePrometheusRw      InputExecInputType = "prometheus_rw"
	InputExecInputTypeAppscope          InputExecInputType = "appscope"
	InputExecInputTypeGooglePubsub      InputExecInputType = "google_pubsub"
	InputExecInputTypeOpenTelemetry     InputExecInputType = "open_telemetry"
	InputExecInputTypeDatadogAgent      InputExecInputType = "datadog_agent"
	InputExecInputTypeWef               InputExecInputType = "wef"
	InputExecInputTypeDatagen           InputExecInputType = "datagen"
	InputExecInputTypeCribl             InputExecInputType = "cribl"
	InputExecInputTypeCriblmetrics      InputExecInputType = "criblmetrics"
	InputExecInputTypeCriblHTTP         InputExecInputType = "cribl_http"
	InputExecInputTypeCriblTCP          InputExecInputType = "cribl_tcp"
	InputExecInputTypeWinEventLogs      InputExecInputType = "win_event_logs"
	InputExecInputTypeSystemMetrics     InputExecInputType = "system_metrics"
	InputExecInputTypeWindowsMetrics    InputExecInputType = "windows_metrics"
	InputExecInputTypeSystemState       InputExecInputType = "system_state"
	InputExecInputTypeKubeMetrics       InputExecInputType = "kube_metrics"
	InputExecInputTypeKubeLogs          InputExecInputType = "kube_logs"
	InputExecInputTypeKubeEvents        InputExecInputType = "kube_events"
	InputExecInputTypeExec              InputExecInputType = "exec"
	InputExecInputTypeSplunkSearch      InputExecInputType = "splunk_search"
	InputExecInputTypeFile              InputExecInputType = "file"
	InputExecInputTypeJournalFiles      InputExecInputType = "journal_files"
)

func (e InputExecInputType) ToPointer() *InputExecInputType {
	return &e
}

func (e *InputExecInputType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "splunk":
		fallthrough
	case "splunk_hec":
		fallthrough
	case "syslog":
		fallthrough
	case "tcpjson":
		fallthrough
	case "grafana":
		fallthrough
	case "loki":
		fallthrough
	case "http":
		fallthrough
	case "http_raw":
		fallthrough
	case "firehose":
		fallthrough
	case "elastic":
		fallthrough
	case "kafka":
		fallthrough
	case "confluent_cloud":
		fallthrough
	case "msk":
		fallthrough
	case "kinesis":
		fallthrough
	case "eventhub":
		fallthrough
	case "azure_blob":
		fallthrough
	case "metrics":
		fallthrough
	case "sqs":
		fallthrough
	case "s3":
		fallthrough
	case "snmp":
		fallthrough
	case "crowdstrike":
		fallthrough
	case "tcp":
		fallthrough
	case "raw_udp":
		fallthrough
	case "office365_service":
		fallthrough
	case "office365_mgmt":
		fallthrough
	case "office365_msg_trace":
		fallthrough
	case "prometheus":
		fallthrough
	case "edge_prometheus":
		fallthrough
	case "prometheus_rw":
		fallthrough
	case "appscope":
		fallthrough
	case "google_pubsub":
		fallthrough
	case "open_telemetry":
		fallthrough
	case "datadog_agent":
		fallthrough
	case "wef":
		fallthrough
	case "datagen":
		fallthrough
	case "cribl":
		fallthrough
	case "criblmetrics":
		fallthrough
	case "cribl_http":
		fallthrough
	case "cribl_tcp":
		fallthrough
	case "win_event_logs":
		fallthrough
	case "system_metrics":
		fallthrough
	case "windows_metrics":
		fallthrough
	case "system_state":
		fallthrough
	case "kube_metrics":
		fallthrough
	case "kube_logs":
		fallthrough
	case "kube_events":
		fallthrough
	case "exec":
		fallthrough
	case "splunk_search":
		fallthrough
	case "file":
		fallthrough
	case "journal_files":
		*e = InputExecInputType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputExecInputType: %v", v)
	}
}

type InputExec struct {
	// A list of event breaking rulesets that will be applied, in order, to the input data stream.
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// Command to execute; supports Bourne shell (or CMD on Windows) syntax
	Command string `json:"command"`
	// Direct connections to Destinations, optionally via a Pipeline or a Pack.
	Connections []InputExecConnections `json:"connections,omitempty"`
	// Cron schedule to execute the command on.
	CronSchedule *string `json:"cronSchedule,omitempty"`
	// Enable/disable this input
	Disabled *bool `json:"disabled,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Unique ID for this input
	ID *string `json:"id,omitempty"`
	// Interval between command executions in seconds.
	Interval *int64 `json:"interval,omitempty"`
	// Fields to add to events from this input.
	Metadata                       []InputExecMetadata                      `json:"metadata,omitempty"`
	OptionalFieldsInGeneralSection *InputExecOptionalFieldsInGeneralSection `json:"optionalFieldsInGeneralSection,omitempty"`
	// Pipeline to process data from this Source before sending it through the Routes.
	Pipeline *string      `json:"pipeline,omitempty"`
	Pq       *InputExecPq `json:"pq,omitempty"`
	// For details on Persistent Queues, see: [https://docs.cribl.io/stream/persistent-queues](https://docs.cribl.io/stream/persistent-queues)
	PqEnabled *bool `json:"pqEnabled,omitempty"`
	// Maximum number of retry attempts in the event that the command fails.
	Retries *int64 `json:"retries,omitempty"`
	// Select a schedule type; either an interval (in seconds) or a cron-style schedule.
	ScheduleType *InputExecScheduleType `json:"scheduleType,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitempty"`
	// The amount of time (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel, before flushing the data stream out, as-is, to the Pipelines.
	StaleChannelFlushMs *int64 `json:"staleChannelFlushMs,omitempty"`
	// Add tags for filtering and grouping in @{product}.
	Streamtags []string           `json:"streamtags,omitempty"`
	Type       InputExecInputType `json:"type"`
}
