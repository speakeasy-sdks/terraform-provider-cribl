// Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"fmt"
)

// OutputAzureEventhubAcknowledgments - Control the number of required acknowledgments
type OutputAzureEventhubAcknowledgments int64

const (
	OutputAzureEventhubAcknowledgmentsOne    OutputAzureEventhubAcknowledgments = 1
	OutputAzureEventhubAcknowledgmentsZero   OutputAzureEventhubAcknowledgments = 0
	OutputAzureEventhubAcknowledgmentsMinus1 OutputAzureEventhubAcknowledgments = -1
)

func (e OutputAzureEventhubAcknowledgments) ToPointer() *OutputAzureEventhubAcknowledgments {
	return &e
}

func (e *OutputAzureEventhubAcknowledgments) UnmarshalJSON(data []byte) error {
	var v int64
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case 1:
		fallthrough
	case 0:
		fallthrough
	case -1:
		*e = OutputAzureEventhubAcknowledgments(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureEventhubAcknowledgments: %v", v)
	}
}

// OutputAzureEventhubRecordDataFormat - Format to use to serialize events before writing to the Event Hubs Kafka brokers.
type OutputAzureEventhubRecordDataFormat string

const (
	OutputAzureEventhubRecordDataFormatJSON OutputAzureEventhubRecordDataFormat = "json"
	OutputAzureEventhubRecordDataFormatRaw  OutputAzureEventhubRecordDataFormat = "raw"
)

func (e OutputAzureEventhubRecordDataFormat) ToPointer() *OutputAzureEventhubRecordDataFormat {
	return &e
}

func (e *OutputAzureEventhubRecordDataFormat) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "json":
		fallthrough
	case "raw":
		*e = OutputAzureEventhubRecordDataFormat(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureEventhubRecordDataFormat: %v", v)
	}
}

// OutputAzureEventhubBackpressureBehavior - Whether to block, drop, or queue events when all receivers are exerting backpressure.
type OutputAzureEventhubBackpressureBehavior string

const (
	OutputAzureEventhubBackpressureBehaviorQueue OutputAzureEventhubBackpressureBehavior = "queue"
	OutputAzureEventhubBackpressureBehaviorDrop  OutputAzureEventhubBackpressureBehavior = "drop"
	OutputAzureEventhubBackpressureBehaviorBlock OutputAzureEventhubBackpressureBehavior = "block"
)

func (e OutputAzureEventhubBackpressureBehavior) ToPointer() *OutputAzureEventhubBackpressureBehavior {
	return &e
}

func (e *OutputAzureEventhubBackpressureBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "queue":
		fallthrough
	case "drop":
		fallthrough
	case "block":
		*e = OutputAzureEventhubBackpressureBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureEventhubBackpressureBehavior: %v", v)
	}
}

// OutputAzureEventhubCompression - Codec to use to compress the persisted data.
type OutputAzureEventhubCompression string

const (
	OutputAzureEventhubCompressionNone OutputAzureEventhubCompression = "none"
	OutputAzureEventhubCompressionGzip OutputAzureEventhubCompression = "gzip"
)

func (e OutputAzureEventhubCompression) ToPointer() *OutputAzureEventhubCompression {
	return &e
}

func (e *OutputAzureEventhubCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = OutputAzureEventhubCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureEventhubCompression: %v", v)
	}
}

type OutputAzureEventhubPqControls struct {
}

// OutputAzureEventhubQueueFullBehavior - Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
type OutputAzureEventhubQueueFullBehavior string

const (
	OutputAzureEventhubQueueFullBehaviorBlock OutputAzureEventhubQueueFullBehavior = "block"
	OutputAzureEventhubQueueFullBehaviorDrop  OutputAzureEventhubQueueFullBehavior = "drop"
)

func (e OutputAzureEventhubQueueFullBehavior) ToPointer() *OutputAzureEventhubQueueFullBehavior {
	return &e
}

func (e *OutputAzureEventhubQueueFullBehavior) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "block":
		fallthrough
	case "drop":
		*e = OutputAzureEventhubQueueFullBehavior(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureEventhubQueueFullBehavior: %v", v)
	}
}

// OutputAzureEventhubAuthenticationSASLMechanism - SASL authentication mechanism to use
type OutputAzureEventhubAuthenticationSASLMechanism string

const (
	OutputAzureEventhubAuthenticationSASLMechanismPlain       OutputAzureEventhubAuthenticationSASLMechanism = "plain"
	OutputAzureEventhubAuthenticationSASLMechanismOauthbearer OutputAzureEventhubAuthenticationSASLMechanism = "oauthbearer"
)

func (e OutputAzureEventhubAuthenticationSASLMechanism) ToPointer() *OutputAzureEventhubAuthenticationSASLMechanism {
	return &e
}

func (e *OutputAzureEventhubAuthenticationSASLMechanism) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "plain":
		fallthrough
	case "oauthbearer":
		*e = OutputAzureEventhubAuthenticationSASLMechanism(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureEventhubAuthenticationSASLMechanism: %v", v)
	}
}

// OutputAzureEventhubAuthentication - Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
type OutputAzureEventhubAuthentication struct {
	// Enable authentication.
	Disabled bool `json:"disabled"`
	// SASL authentication mechanism to use
	Mechanism *OutputAzureEventhubAuthenticationSASLMechanism `json:"mechanism,omitempty"`
}

type OutputAzureEventhubTLSSettingsClientSide struct {
	Disabled bool `json:"disabled"`
	// Reject certs that are not authorized by a CA in the CA certificate path, or by another trusted CA (e.g., the system's CA).
	RejectUnauthorized *bool `json:"rejectUnauthorized,omitempty"`
}

type OutputAzureEventhubType string

const (
	OutputAzureEventhubTypeAzureEventhub OutputAzureEventhubType = "azure_eventhub"
)

func (e OutputAzureEventhubType) ToPointer() *OutputAzureEventhubType {
	return &e
}

func (e *OutputAzureEventhubType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "azure_eventhub":
		*e = OutputAzureEventhubType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for OutputAzureEventhubType: %v", v)
	}
}

type OutputAzureEventhub struct {
	// Control the number of required acknowledgments
	Ack *OutputAzureEventhubAcknowledgments `json:"ack,omitempty"`
	// Maximum time to wait for Kafka to respond to an authentication request
	AuthenticationTimeout *int64 `json:"authenticationTimeout,omitempty"`
	// List of Event Hubs Kafka brokers to connect to, eg. yourdomain.servicebus.windows.net:9093. The hostname can be found in the host portion of the primary or secondary connection string in Shared Access Policies.
	Brokers []string `json:"brokers"`
	// Maximum time to wait for a connection to complete successfully
	ConnectionTimeout *int64 `json:"connectionTimeout,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Maximum number of events in a batch before forcing a flush.
	FlushEventCount *int64 `json:"flushEventCount,omitempty"`
	// Maximum time between requests. Small values could cause the payload size to be smaller than the configured Max record size.
	FlushPeriodSec *int64 `json:"flushPeriodSec,omitempty"`
	// Format to use to serialize events before writing to the Event Hubs Kafka brokers.
	Format *OutputAzureEventhubRecordDataFormat `json:"format,omitempty"`
	// Unique ID for this output
	ID *string `json:"id,omitempty"`
	// Maximum size (KB) of each record batch before compression. Setting should be < message.max.bytes settings in Event Hubs brokers.
	MaxRecordSizeKB *int64 `json:"maxRecordSizeKB,omitempty"`
	// If messages are failing, you can set the maximum number of retries as high as 100 to prevent loss of data.
	MaxRetries *int64 `json:"maxRetries,omitempty"`
	// Whether to block, drop, or queue events when all receivers are exerting backpressure.
	OnBackpressure *OutputAzureEventhubBackpressureBehavior `json:"onBackpressure,omitempty"`
	// Pipeline to process data before sending out to this output.
	Pipeline *string `json:"pipeline,omitempty"`
	// Codec to use to compress the persisted data.
	PqCompress *OutputAzureEventhubCompression `json:"pqCompress,omitempty"`
	PqControls *OutputAzureEventhubPqControls  `json:"pqControls,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	PqMaxFileSize *string `json:"pqMaxFileSize,omitempty"`
	// The maximum amount of disk space the queue is allowed to consume. Once reached, the system stops queueing and applies the fallback Queue-full behavior. Enter a numeral with units of KB, MB, etc.
	PqMaxSize *string `json:"pqMaxSize,omitempty"`
	// Whether to block or drop events when the queue is exerting backpressure (full capacity or low disk). 'Block' is the same behavior as non-PQ blocking. 'Drop new data' throws away incoming data, while leaving the contents of the PQ unchanged.
	PqOnBackpressure *OutputAzureEventhubQueueFullBehavior `json:"pqOnBackpressure,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/<output-id>.
	PqPath *string `json:"pqPath,omitempty"`
	// Toggle this off to forward new events to receiver(s) before queue is flushed. Otherwise, default drain behavior is FIFO (first in, first out).
	PqStrictOrdering *bool `json:"pqStrictOrdering,omitempty"`
	// Specifies a time window during which @{product} can reauthenticate if needed. Creates the window measuring backwards from the moment when credentials are set to expire.
	ReauthenticationThreshold *int64 `json:"reauthenticationThreshold,omitempty"`
	// Maximum time to wait for Kafka to respond to a request
	RequestTimeout *int64 `json:"requestTimeout,omitempty"`
	// Authentication parameters to use when connecting to brokers. Using TLS is highly recommended.
	Sasl *OutputAzureEventhubAuthentication `json:"sasl,omitempty"`
	// Add tags for filtering and grouping in @{product}.
	Streamtags []string `json:"streamtags,omitempty"`
	// Set of fields to automatically add to events using this output. E.g.: cribl_pipe, c*. Wildcards supported.
	SystemFields []string                                  `json:"systemFields,omitempty"`
	TLS          *OutputAzureEventhubTLSSettingsClientSide `json:"tls,omitempty"`
	// The name of the Event Hub (a.k.a. Kafka Topic) to publish events. Can be overwritten using field __topicOut.
	Topic string                   `json:"topic"`
	Type  *OutputAzureEventhubType `json:"type,omitempty"`
}
