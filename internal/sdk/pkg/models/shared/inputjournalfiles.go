// Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"fmt"
)

type InputJournalFilesConnections struct {
	// Select a Destination.
	Output string `json:"output"`
	// Select Pipeline or Pack. Optional.
	Pipeline *string `json:"pipeline,omitempty"`
}

type InputJournalFilesMetadata struct {
	// Field name
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

// InputJournalFilesPqCompression - Codec to use to compress the persisted data.
type InputJournalFilesPqCompression string

const (
	InputJournalFilesPqCompressionNone InputJournalFilesPqCompression = "none"
	InputJournalFilesPqCompressionGzip InputJournalFilesPqCompression = "gzip"
)

func (e InputJournalFilesPqCompression) ToPointer() *InputJournalFilesPqCompression {
	return &e
}

func (e *InputJournalFilesPqCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputJournalFilesPqCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputJournalFilesPqCompression: %v", v)
	}
}

// InputJournalFilesPqMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputJournalFilesPqMode string

const (
	InputJournalFilesPqModeSmart  InputJournalFilesPqMode = "smart"
	InputJournalFilesPqModeAlways InputJournalFilesPqMode = "always"
)

func (e InputJournalFilesPqMode) ToPointer() *InputJournalFilesPqMode {
	return &e
}

func (e *InputJournalFilesPqMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputJournalFilesPqMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputJournalFilesPqMode: %v", v)
	}
}

type InputJournalFilesPq struct {
	// The number of events to send downstream before committing that Stream has read them.
	CommitFrequency *int64 `json:"commitFrequency,omitempty"`
	// Codec to use to compress the persisted data.
	Compress *InputJournalFilesPqCompression `json:"compress,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk.
	MaxBufferSize *int64 `json:"maxBufferSize,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	MaxFileSize *string `json:"maxFileSize,omitempty"`
	// The maximum amount of disk space the queue is allowed to consume. Once reached, the system stops queueing and applies the fallback Queue-full behavior. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `json:"maxSize,omitempty"`
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputJournalFilesPqMode `json:"mode,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>.
	Path *string `json:"path,omitempty"`
}

type InputJournalFilesRules struct {
	// Optional description of this rule's purpose
	Description *string `json:"description,omitempty"`
	// JavaScript expression applied to Journal objects. Return 'true' to include it.
	Filter string `json:"filter"`
}

type InputJournalFilesInputType string

const (
	InputJournalFilesInputTypeSplunk            InputJournalFilesInputType = "splunk"
	InputJournalFilesInputTypeSplunkHec         InputJournalFilesInputType = "splunk_hec"
	InputJournalFilesInputTypeSyslog            InputJournalFilesInputType = "syslog"
	InputJournalFilesInputTypeTcpjson           InputJournalFilesInputType = "tcpjson"
	InputJournalFilesInputTypeGrafana           InputJournalFilesInputType = "grafana"
	InputJournalFilesInputTypeLoki              InputJournalFilesInputType = "loki"
	InputJournalFilesInputTypeHTTP              InputJournalFilesInputType = "http"
	InputJournalFilesInputTypeHTTPRaw           InputJournalFilesInputType = "http_raw"
	InputJournalFilesInputTypeFirehose          InputJournalFilesInputType = "firehose"
	InputJournalFilesInputTypeElastic           InputJournalFilesInputType = "elastic"
	InputJournalFilesInputTypeKafka             InputJournalFilesInputType = "kafka"
	InputJournalFilesInputTypeConfluentCloud    InputJournalFilesInputType = "confluent_cloud"
	InputJournalFilesInputTypeMsk               InputJournalFilesInputType = "msk"
	InputJournalFilesInputTypeKinesis           InputJournalFilesInputType = "kinesis"
	InputJournalFilesInputTypeEventhub          InputJournalFilesInputType = "eventhub"
	InputJournalFilesInputTypeAzureBlob         InputJournalFilesInputType = "azure_blob"
	InputJournalFilesInputTypeMetrics           InputJournalFilesInputType = "metrics"
	InputJournalFilesInputTypeSqs               InputJournalFilesInputType = "sqs"
	InputJournalFilesInputTypeS3                InputJournalFilesInputType = "s3"
	InputJournalFilesInputTypeSnmp              InputJournalFilesInputType = "snmp"
	InputJournalFilesInputTypeCrowdstrike       InputJournalFilesInputType = "crowdstrike"
	InputJournalFilesInputTypeTCP               InputJournalFilesInputType = "tcp"
	InputJournalFilesInputTypeRawUDP            InputJournalFilesInputType = "raw_udp"
	InputJournalFilesInputTypeOffice365Service  InputJournalFilesInputType = "office365_service"
	InputJournalFilesInputTypeOffice365Mgmt     InputJournalFilesInputType = "office365_mgmt"
	InputJournalFilesInputTypeOffice365MsgTrace InputJournalFilesInputType = "office365_msg_trace"
	InputJournalFilesInputTypePrometheus        InputJournalFilesInputType = "prometheus"
	InputJournalFilesInputTypeEdgePrometheus    InputJournalFilesInputType = "edge_prometheus"
	InputJournalFilesInputTypePrometheusRw      InputJournalFilesInputType = "prometheus_rw"
	InputJournalFilesInputTypeAppscope          InputJournalFilesInputType = "appscope"
	InputJournalFilesInputTypeGooglePubsub      InputJournalFilesInputType = "google_pubsub"
	InputJournalFilesInputTypeOpenTelemetry     InputJournalFilesInputType = "open_telemetry"
	InputJournalFilesInputTypeDatadogAgent      InputJournalFilesInputType = "datadog_agent"
	InputJournalFilesInputTypeWef               InputJournalFilesInputType = "wef"
	InputJournalFilesInputTypeDatagen           InputJournalFilesInputType = "datagen"
	InputJournalFilesInputTypeCribl             InputJournalFilesInputType = "cribl"
	InputJournalFilesInputTypeCriblmetrics      InputJournalFilesInputType = "criblmetrics"
	InputJournalFilesInputTypeCriblHTTP         InputJournalFilesInputType = "cribl_http"
	InputJournalFilesInputTypeCriblTCP          InputJournalFilesInputType = "cribl_tcp"
	InputJournalFilesInputTypeWinEventLogs      InputJournalFilesInputType = "win_event_logs"
	InputJournalFilesInputTypeSystemMetrics     InputJournalFilesInputType = "system_metrics"
	InputJournalFilesInputTypeWindowsMetrics    InputJournalFilesInputType = "windows_metrics"
	InputJournalFilesInputTypeSystemState       InputJournalFilesInputType = "system_state"
	InputJournalFilesInputTypeKubeMetrics       InputJournalFilesInputType = "kube_metrics"
	InputJournalFilesInputTypeKubeLogs          InputJournalFilesInputType = "kube_logs"
	InputJournalFilesInputTypeKubeEvents        InputJournalFilesInputType = "kube_events"
	InputJournalFilesInputTypeExec              InputJournalFilesInputType = "exec"
	InputJournalFilesInputTypeSplunkSearch      InputJournalFilesInputType = "splunk_search"
	InputJournalFilesInputTypeFile              InputJournalFilesInputType = "file"
	InputJournalFilesInputTypeJournalFiles      InputJournalFilesInputType = "journal_files"
)

func (e InputJournalFilesInputType) ToPointer() *InputJournalFilesInputType {
	return &e
}

func (e *InputJournalFilesInputType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "splunk":
		fallthrough
	case "splunk_hec":
		fallthrough
	case "syslog":
		fallthrough
	case "tcpjson":
		fallthrough
	case "grafana":
		fallthrough
	case "loki":
		fallthrough
	case "http":
		fallthrough
	case "http_raw":
		fallthrough
	case "firehose":
		fallthrough
	case "elastic":
		fallthrough
	case "kafka":
		fallthrough
	case "confluent_cloud":
		fallthrough
	case "msk":
		fallthrough
	case "kinesis":
		fallthrough
	case "eventhub":
		fallthrough
	case "azure_blob":
		fallthrough
	case "metrics":
		fallthrough
	case "sqs":
		fallthrough
	case "s3":
		fallthrough
	case "snmp":
		fallthrough
	case "crowdstrike":
		fallthrough
	case "tcp":
		fallthrough
	case "raw_udp":
		fallthrough
	case "office365_service":
		fallthrough
	case "office365_mgmt":
		fallthrough
	case "office365_msg_trace":
		fallthrough
	case "prometheus":
		fallthrough
	case "edge_prometheus":
		fallthrough
	case "prometheus_rw":
		fallthrough
	case "appscope":
		fallthrough
	case "google_pubsub":
		fallthrough
	case "open_telemetry":
		fallthrough
	case "datadog_agent":
		fallthrough
	case "wef":
		fallthrough
	case "datagen":
		fallthrough
	case "cribl":
		fallthrough
	case "criblmetrics":
		fallthrough
	case "cribl_http":
		fallthrough
	case "cribl_tcp":
		fallthrough
	case "win_event_logs":
		fallthrough
	case "system_metrics":
		fallthrough
	case "windows_metrics":
		fallthrough
	case "system_state":
		fallthrough
	case "kube_metrics":
		fallthrough
	case "kube_logs":
		fallthrough
	case "kube_events":
		fallthrough
	case "exec":
		fallthrough
	case "splunk_search":
		fallthrough
	case "file":
		fallthrough
	case "journal_files":
		*e = InputJournalFilesInputType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputJournalFilesInputType: %v", v)
	}
}

type InputJournalFiles struct {
	// Direct connections to Destinations, optionally via a Pipeline or a Pack.
	Connections []InputJournalFilesConnections `json:"connections,omitempty"`
	// Skip log messages that are not part of the current boot session.
	CurrentBoot *bool `json:"currentBoot,omitempty"`
	// Enable/disable this input
	Disabled *bool `json:"disabled,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Unique ID for this input
	ID *string `json:"id,omitempty"`
	// Time, in seconds, between scanning for journals.
	Interval *int64 `json:"interval,omitempty"`
	// The full path of discovered journals are matched against this wildcard list.
	Journals []string `json:"journals"`
	// The maximum log message age, in duration form (e.g,: 60s, 4h, 3d, 1w).  Default of no value will apply no max age filters.
	MaxAgeDur *string `json:"maxAgeDur,omitempty"`
	// Fields to add to events from this input.
	Metadata []InputJournalFilesMetadata `json:"metadata,omitempty"`
	// Directory path to search for journals. Environment variables will be resolved, e.g. $CRIBL_EDGE_FS_ROOT/var/log/journal/$MACHINE_ID.
	Path string `json:"path"`
	// Pipeline to process data from this Source before sending it through the Routes.
	Pipeline *string              `json:"pipeline,omitempty"`
	Pq       *InputJournalFilesPq `json:"pq,omitempty"`
	// For details on Persistent Queues, see: [https://docs.cribl.io/stream/persistent-queues](https://docs.cribl.io/stream/persistent-queues)
	PqEnabled *bool `json:"pqEnabled,omitempty"`
	// Add rules to decide which journal objects to allow. Events are generated if no rules are given or if all the rules' expressions evaluate to true.
	Rules []InputJournalFilesRules `json:"rules,omitempty"`
	// Select whether to send data to Routes, or directly to Destinations.
	SendToRoutes *bool `json:"sendToRoutes,omitempty"`
	// Add tags for filtering and grouping in @{product}.
	Streamtags []string                    `json:"streamtags,omitempty"`
	Type       *InputJournalFilesInputType `json:"type,omitempty"`
}
